{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(14)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Dropout, Activation, Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers \n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 61)\n"
     ]
    }
   ],
   "source": [
    "dfCenter = pd.read_csv('datasets/face_center.csv')\n",
    "dfCenter2 = pd.read_csv('datasets/face_center2.csv')\n",
    "dfCenter = dfCenter.append(dfCenter2, ignore_index = True)\n",
    "\n",
    "dfRight = pd.read_csv('datasets/face_right.csv')\n",
    "dfRight2 = pd.read_csv('datasets/face_right2.csv')\n",
    "dfRight = dfRight.append(dfRight2, ignore_index = True)\n",
    "\n",
    "dfLeft = pd.read_csv('datasets/face_left.csv')\n",
    "dfLeft2 = pd.read_csv('datasets/face_left2.csv')\n",
    "dfLeft = dfLeft.append(dfLeft2, ignore_index = True)\n",
    "\n",
    "dfUp = pd.read_csv('datasets/face_up.csv')\n",
    "dfUp2 = pd.read_csv('datasets/face_up2.csv')\n",
    "dfUp = dfUp.append(dfUp2, ignore_index = True)\n",
    "\n",
    "dfDown = pd.read_csv('datasets/face_down.csv')\n",
    "dfDown2 = pd.read_csv('datasets/face_down2.csv')\n",
    "dfDown = dfDown.append(dfDown2, ignore_index = True)\n",
    "\n",
    "dfUpRight = pd.read_csv('datasets/face_up_right.csv')\n",
    "dfUpRight2 = pd.read_csv('datasets/face_up_right2.csv')\n",
    "dfUpRight = dfUpRight.append(dfUpRight2, ignore_index = True)\n",
    "\n",
    "dfUpLeft = pd.read_csv('datasets/face_up_left.csv')\n",
    "dfUpLeft2 = pd.read_csv('datasets/face_up_left2.csv')\n",
    "dfUpLeft = dfUpLeft.append(dfUpLeft2, ignore_index = True)\n",
    "\n",
    "dfDownRight = pd.read_csv('datasets/face_down_right.csv')\n",
    "dfDownRight2 = pd.read_csv('datasets/face_down_right2.csv')\n",
    "dfDownRight = dfDownRight.append(dfDownRight2, ignore_index = True)\n",
    "\n",
    "dfDownLeft = pd.read_csv('datasets/face_down_left.csv')\n",
    "dfDownLeft2 = pd.read_csv('datasets/face_down_left2.csv')\n",
    "dfDownLeft = dfDownLeft.append(dfDownLeft2, ignore_index = True)\n",
    "\n",
    "columns = list(dfCenter)\n",
    "\n",
    "dfCenter['RESULT'] = 0\n",
    "dfRight['RESULT'] = 1\n",
    "dfLeft['RESULT'] = 2\n",
    "dfUp['RESULT'] = 3\n",
    "dfDown['RESULT'] = 4\n",
    "dfUpRight['RESULT'] = 5\n",
    "dfUpLeft['RESULT'] = 6\n",
    "dfDownRight['RESULT'] = 7\n",
    "dfDownLeft['RESULT'] = 8\n",
    "\n",
    "\n",
    "df = dfCenter.append(dfRight, ignore_index=True).append(dfLeft, ignore_index = True)\n",
    "df = df.append(dfUp, ignore_index = True).append(dfDown, ignore_index = True)\n",
    "df = df.append(dfUpRight, ignore_index = True).append(dfUpLeft, ignore_index = True)\n",
    "df = df.append(dfDownRight, ignore_index = True).append(dfDownLeft, ignore_index = True)\n",
    "\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.870639</td>\n",
       "      <td>0.778903</td>\n",
       "      <td>0.725278</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.661416</td>\n",
       "      <td>0.679687</td>\n",
       "      <td>0.725736</td>\n",
       "      <td>0.733129</td>\n",
       "      <td>0.697956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440451</td>\n",
       "      <td>0.461847</td>\n",
       "      <td>0.483469</td>\n",
       "      <td>0.492717</td>\n",
       "      <td>0.535039</td>\n",
       "      <td>0.545349</td>\n",
       "      <td>0.529865</td>\n",
       "      <td>0.501872</td>\n",
       "      <td>0.437781</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873671</td>\n",
       "      <td>0.781486</td>\n",
       "      <td>0.735074</td>\n",
       "      <td>0.683443</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.673143</td>\n",
       "      <td>0.724177</td>\n",
       "      <td>0.729398</td>\n",
       "      <td>0.696364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>0.481957</td>\n",
       "      <td>0.495796</td>\n",
       "      <td>0.492139</td>\n",
       "      <td>0.528186</td>\n",
       "      <td>0.541326</td>\n",
       "      <td>0.529552</td>\n",
       "      <td>0.497978</td>\n",
       "      <td>0.431634</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877431</td>\n",
       "      <td>0.790890</td>\n",
       "      <td>0.744683</td>\n",
       "      <td>0.692465</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>0.677805</td>\n",
       "      <td>0.718668</td>\n",
       "      <td>0.727266</td>\n",
       "      <td>0.696576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448371</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.488073</td>\n",
       "      <td>0.494257</td>\n",
       "      <td>0.521760</td>\n",
       "      <td>0.529427</td>\n",
       "      <td>0.515435</td>\n",
       "      <td>0.493970</td>\n",
       "      <td>0.433165</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881703</td>\n",
       "      <td>0.792698</td>\n",
       "      <td>0.741344</td>\n",
       "      <td>0.697454</td>\n",
       "      <td>0.673473</td>\n",
       "      <td>0.686590</td>\n",
       "      <td>0.721158</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>0.687107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.447417</td>\n",
       "      <td>0.465064</td>\n",
       "      <td>0.479192</td>\n",
       "      <td>0.519957</td>\n",
       "      <td>0.540319</td>\n",
       "      <td>0.528465</td>\n",
       "      <td>0.506383</td>\n",
       "      <td>0.439765</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881703</td>\n",
       "      <td>0.794662</td>\n",
       "      <td>0.747706</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.679918</td>\n",
       "      <td>0.693795</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.732642</td>\n",
       "      <td>0.692457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448210</td>\n",
       "      <td>0.467434</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.482802</td>\n",
       "      <td>0.528204</td>\n",
       "      <td>0.543669</td>\n",
       "      <td>0.532557</td>\n",
       "      <td>0.512542</td>\n",
       "      <td>0.446091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6  \\\n",
       "8995  1.0  0.870639  0.778903  0.725278  0.680233  0.661416  0.679687   \n",
       "8996  1.0  0.873671  0.781486  0.735074  0.683443  0.655249  0.673143   \n",
       "8997  1.0  0.877431  0.790890  0.744683  0.692465  0.664408  0.677805   \n",
       "8998  1.0  0.881703  0.792698  0.741344  0.697454  0.673473  0.686590   \n",
       "8999  1.0  0.881703  0.794662  0.747706  0.701630  0.679918  0.693795   \n",
       "\n",
       "             7         8         9  ...        51        52        53  \\\n",
       "8995  0.725736  0.733129  0.697956  ...  0.440451  0.461847  0.483469   \n",
       "8996  0.724177  0.729398  0.696364  ...  0.465730  0.481957  0.495796   \n",
       "8997  0.718668  0.727266  0.696576  ...  0.448371  0.470152  0.488073   \n",
       "8998  0.721158  0.718938  0.687107  ...  0.426923  0.447417  0.465064   \n",
       "8999  0.731132  0.732642  0.692457  ...  0.448210  0.467434  0.485004   \n",
       "\n",
       "            54        55        56        57        58        59  RESULT  \n",
       "8995  0.492717  0.535039  0.545349  0.529865  0.501872  0.437781       8  \n",
       "8996  0.492139  0.528186  0.541326  0.529552  0.497978  0.431634       8  \n",
       "8997  0.494257  0.521760  0.529427  0.515435  0.493970  0.433165       8  \n",
       "8998  0.479192  0.519957  0.540319  0.528465  0.506383  0.439765       8  \n",
       "8999  0.482802  0.528204  0.543669  0.532557  0.512542  0.446091       8  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 61)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input data and desired output, and then split training and test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = df[columns]\n",
    "y = df['RESULT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=14)\n",
    "\n",
    "c = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "\n",
    "n_classes = 9\n",
    "#one hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print (y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values \n",
    "Y_train_np = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_train).astype('float32')\n",
    "Y = np.array(y_train)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 60)\n",
      "(1800, 9)\n",
      "(7200, 60, 1)\n",
      "(1800, 60, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7200, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train_np = np.expand_dims(X_train_np, axis=2)\n",
    "print(X_train_np.shape)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "print(X_test.shape)\n",
    "#Y_train_np = np.expand_dims(Y_train_np, axis=2)\n",
    "Y_train_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(32, 3, padding ='same', input_shape=(60,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(32, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "  \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "  \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.00125),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def evaluate(model, batch_size=128, epochs=100):\n",
    "    model.summary()\n",
    "    history = model.fit(X_train_np, Y_train_np, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 60, 32)            3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 60, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 73,769\n",
      "Trainable params: 73,129\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/100\n",
      "7200/7200 [==============================] - 25s 3ms/step - loss: 2.0689 - acc: 0.2999 - val_loss: 1.9420 - val_acc: 0.4161\n",
      "Epoch 2/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.8858 - acc: 0.4332 - val_loss: 1.7842 - val_acc: 0.4544\n",
      "Epoch 3/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.7465 - acc: 0.5086 - val_loss: 1.6563 - val_acc: 0.4800\n",
      "Epoch 4/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.6328 - acc: 0.5750 - val_loss: 1.5495 - val_acc: 0.5039\n",
      "Epoch 5/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.5335 - acc: 0.6265 - val_loss: 1.4609 - val_acc: 0.5400\n",
      "Epoch 6/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.4454 - acc: 0.6743 - val_loss: 1.3836 - val_acc: 0.6133\n",
      "Epoch 7/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.3661 - acc: 0.7217 - val_loss: 1.3099 - val_acc: 0.6906\n",
      "Epoch 8/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 1.2873 - acc: 0.7519 - val_loss: 1.2449 - val_acc: 0.7378\n",
      "Epoch 9/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.2178 - acc: 0.7811 - val_loss: 1.1742 - val_acc: 0.7900\n",
      "Epoch 10/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.1517 - acc: 0.7988 - val_loss: 1.1161 - val_acc: 0.8156\n",
      "Epoch 11/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.0920 - acc: 0.8038 - val_loss: 1.0469 - val_acc: 0.8400\n",
      "Epoch 12/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 1.0322 - acc: 0.8174 - val_loss: 0.9918 - val_acc: 0.8456\n",
      "Epoch 13/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.9847 - acc: 0.8300 - val_loss: 0.9405 - val_acc: 0.8506\n",
      "Epoch 14/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.9416 - acc: 0.8299 - val_loss: 0.8870 - val_acc: 0.8578\n",
      "Epoch 15/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.8929 - acc: 0.8386 - val_loss: 0.8484 - val_acc: 0.8567\n",
      "Epoch 16/100\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.8586 - acc: 0.8374 - val_loss: 0.8020 - val_acc: 0.8611\n",
      "Epoch 17/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.8198 - acc: 0.8451 - val_loss: 0.7705 - val_acc: 0.8617\n",
      "Epoch 18/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.7881 - acc: 0.8475 - val_loss: 0.7363 - val_acc: 0.8622\n",
      "Epoch 19/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.7609 - acc: 0.8518 - val_loss: 0.7111 - val_acc: 0.8639\n",
      "Epoch 20/100\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.7327 - acc: 0.8561 - val_loss: 0.6802 - val_acc: 0.8683\n",
      "Epoch 21/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.7101 - acc: 0.8614 - val_loss: 0.6598 - val_acc: 0.8672\n",
      "Epoch 22/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6883 - acc: 0.8639 - val_loss: 0.6373 - val_acc: 0.8744\n",
      "Epoch 23/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6636 - acc: 0.8694 - val_loss: 0.6174 - val_acc: 0.8772\n",
      "Epoch 24/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6432 - acc: 0.8731 - val_loss: 0.5982 - val_acc: 0.8789\n",
      "Epoch 25/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6246 - acc: 0.8739 - val_loss: 0.5789 - val_acc: 0.8783\n",
      "Epoch 26/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.6047 - acc: 0.8821 - val_loss: 0.5625 - val_acc: 0.8878\n",
      "Epoch 27/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5948 - acc: 0.8807 - val_loss: 0.5499 - val_acc: 0.8867\n",
      "Epoch 28/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5751 - acc: 0.8788 - val_loss: 0.5309 - val_acc: 0.8906\n",
      "Epoch 29/100\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.5646 - acc: 0.8867 - val_loss: 0.5160 - val_acc: 0.8983\n",
      "Epoch 30/100\n",
      "7200/7200 [==============================] - 23s 3ms/step - loss: 0.5487 - acc: 0.8872 - val_loss: 0.5035 - val_acc: 0.8944\n",
      "Epoch 31/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5364 - acc: 0.8906 - val_loss: 0.4915 - val_acc: 0.8994\n",
      "Epoch 32/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.5198 - acc: 0.8949 - val_loss: 0.4788 - val_acc: 0.9033\n",
      "Epoch 33/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.5066 - acc: 0.8962 - val_loss: 0.4685 - val_acc: 0.9089\n",
      "Epoch 34/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.4985 - acc: 0.9026 - val_loss: 0.4546 - val_acc: 0.9061\n",
      "Epoch 35/100\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.4872 - acc: 0.9010 - val_loss: 0.4462 - val_acc: 0.9133\n",
      "Epoch 36/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.4728 - acc: 0.9026 - val_loss: 0.4347 - val_acc: 0.9189\n",
      "Epoch 37/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4637 - acc: 0.9064 - val_loss: 0.4237 - val_acc: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.4586 - acc: 0.9075 - val_loss: 0.4193 - val_acc: 0.9239\n",
      "Epoch 39/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4444 - acc: 0.9131 - val_loss: 0.4043 - val_acc: 0.9228\n",
      "Epoch 40/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4370 - acc: 0.9132 - val_loss: 0.3952 - val_acc: 0.9289\n",
      "Epoch 41/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.4252 - acc: 0.9161 - val_loss: 0.3859 - val_acc: 0.9267\n",
      "Epoch 42/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4168 - acc: 0.9167 - val_loss: 0.3773 - val_acc: 0.9278\n",
      "Epoch 43/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4028 - acc: 0.9192 - val_loss: 0.3698 - val_acc: 0.9317\n",
      "Epoch 44/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4043 - acc: 0.9189 - val_loss: 0.3629 - val_acc: 0.9272\n",
      "Epoch 45/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3912 - acc: 0.9228 - val_loss: 0.3528 - val_acc: 0.9322\n",
      "Epoch 46/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.3876 - acc: 0.9211 - val_loss: 0.3474 - val_acc: 0.9333\n",
      "Epoch 47/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.3762 - acc: 0.9250 - val_loss: 0.3456 - val_acc: 0.9350\n",
      "Epoch 48/100\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.3760 - acc: 0.9260 - val_loss: 0.3331 - val_acc: 0.9356\n",
      "Epoch 49/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.3652 - acc: 0.9279 - val_loss: 0.3249 - val_acc: 0.9317\n",
      "Epoch 50/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3566 - acc: 0.9292 - val_loss: 0.3211 - val_acc: 0.9333\n",
      "Epoch 51/100\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.3525 - acc: 0.9308 - val_loss: 0.3200 - val_acc: 0.9328\n",
      "Epoch 52/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3432 - acc: 0.9307 - val_loss: 0.3073 - val_acc: 0.9383\n",
      "Epoch 53/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3441 - acc: 0.9300 - val_loss: 0.3050 - val_acc: 0.9394\n",
      "Epoch 54/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.3357 - acc: 0.9342 - val_loss: 0.2988 - val_acc: 0.9394\n",
      "Epoch 55/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.3265 - acc: 0.9337 - val_loss: 0.2912 - val_acc: 0.9361\n",
      "Epoch 56/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.3241 - acc: 0.9303 - val_loss: 0.2880 - val_acc: 0.9389\n",
      "Epoch 57/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.3233 - acc: 0.9325 - val_loss: 0.2825 - val_acc: 0.9383\n",
      "Epoch 58/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.3132 - acc: 0.9360 - val_loss: 0.2772 - val_acc: 0.9400\n",
      "Epoch 59/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3099 - acc: 0.9347 - val_loss: 0.2728 - val_acc: 0.9444\n",
      "Epoch 60/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.3018 - acc: 0.9376 - val_loss: 0.2834 - val_acc: 0.9372\n",
      "Epoch 61/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2995 - acc: 0.9379 - val_loss: 0.2654 - val_acc: 0.9422\n",
      "Epoch 62/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2941 - acc: 0.9394 - val_loss: 0.2656 - val_acc: 0.9417\n",
      "Epoch 63/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2899 - acc: 0.9394 - val_loss: 0.2581 - val_acc: 0.9433\n",
      "Epoch 64/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2870 - acc: 0.9390 - val_loss: 0.2521 - val_acc: 0.9467\n",
      "Epoch 65/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2784 - acc: 0.9413 - val_loss: 0.3110 - val_acc: 0.9367\n",
      "Epoch 66/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2770 - acc: 0.9426 - val_loss: 0.2433 - val_acc: 0.9483\n",
      "Epoch 67/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2764 - acc: 0.9413 - val_loss: 0.2400 - val_acc: 0.9472\n",
      "Epoch 68/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2685 - acc: 0.9447 - val_loss: 0.2352 - val_acc: 0.9500\n",
      "Epoch 69/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2673 - acc: 0.9439 - val_loss: 0.2429 - val_acc: 0.9450\n",
      "Epoch 70/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2648 - acc: 0.9437 - val_loss: 0.2295 - val_acc: 0.9494\n",
      "Epoch 71/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.2563 - acc: 0.9449 - val_loss: 0.2336 - val_acc: 0.9500\n",
      "Epoch 72/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2590 - acc: 0.9432 - val_loss: 0.2471 - val_acc: 0.9444\n",
      "Epoch 73/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2505 - acc: 0.9468 - val_loss: 0.2348 - val_acc: 0.9489\n",
      "Epoch 74/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2538 - acc: 0.9471 - val_loss: 0.2323 - val_acc: 0.9456\n",
      "Epoch 75/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2463 - acc: 0.9474 - val_loss: 0.2180 - val_acc: 0.9494\n",
      "Epoch 76/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2429 - acc: 0.9471 - val_loss: 0.2155 - val_acc: 0.9494\n",
      "Epoch 77/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2405 - acc: 0.9462 - val_loss: 0.2200 - val_acc: 0.9478\n",
      "Epoch 78/100\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.2380 - acc: 0.9475 - val_loss: 0.2067 - val_acc: 0.9544\n",
      "Epoch 79/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2348 - acc: 0.9482 - val_loss: 0.2038 - val_acc: 0.9567\n",
      "Epoch 80/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.2328 - acc: 0.9481 - val_loss: 0.2066 - val_acc: 0.9544\n",
      "Epoch 81/100\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.2264 - acc: 0.9501 - val_loss: 0.2000 - val_acc: 0.9539\n",
      "Epoch 82/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2250 - acc: 0.9514 - val_loss: 0.2071 - val_acc: 0.9500\n",
      "Epoch 83/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2206 - acc: 0.9517 - val_loss: 0.2010 - val_acc: 0.9561\n",
      "Epoch 84/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.2205 - acc: 0.9525 - val_loss: 0.1936 - val_acc: 0.9589\n",
      "Epoch 85/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.2190 - acc: 0.9508 - val_loss: 0.1905 - val_acc: 0.9572\n",
      "Epoch 86/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2147 - acc: 0.9536 - val_loss: 0.2146 - val_acc: 0.9528\n",
      "Epoch 87/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2138 - acc: 0.9512 - val_loss: 0.2061 - val_acc: 0.9489\n",
      "Epoch 88/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2075 - acc: 0.9540 - val_loss: 0.2005 - val_acc: 0.9567\n",
      "Epoch 89/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2067 - acc: 0.9549 - val_loss: 0.1833 - val_acc: 0.9583\n",
      "Epoch 90/100\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.2056 - acc: 0.9539 - val_loss: 0.1894 - val_acc: 0.9567\n",
      "Epoch 91/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.2004 - acc: 0.9543 - val_loss: 0.1897 - val_acc: 0.9544\n",
      "Epoch 92/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.2022 - acc: 0.9539 - val_loss: 0.1823 - val_acc: 0.9578\n",
      "Epoch 93/100\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.1971 - acc: 0.9568 - val_loss: 0.1951 - val_acc: 0.9561\n",
      "Epoch 94/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.1924 - acc: 0.9561 - val_loss: 0.2481 - val_acc: 0.9328\n",
      "Epoch 95/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.1960 - acc: 0.9544 - val_loss: 0.1997 - val_acc: 0.9556\n",
      "Epoch 96/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.1916 - acc: 0.9561 - val_loss: 0.1676 - val_acc: 0.9622\n",
      "Epoch 97/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.1901 - acc: 0.9563 - val_loss: 0.1685 - val_acc: 0.9622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.1869 - acc: 0.9581 - val_loss: 0.1800 - val_acc: 0.9600\n",
      "Epoch 99/100\n",
      "7200/7200 [==============================] - 16s 2ms/step - loss: 0.1859 - acc: 0.9569 - val_loss: 0.2172 - val_acc: 0.9389\n",
      "Epoch 100/100\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.1864 - acc: 0.9574 - val_loss: 0.1627 - val_acc: 0.9622\n",
      "Test loss: 0.163\n",
      "Test accuracy: 0.962\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for layers in range(1, 5):\n",
    "model = create_dense()\n",
    "evaluate(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
