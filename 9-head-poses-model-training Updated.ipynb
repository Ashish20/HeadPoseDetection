{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Head poses Model Training\n",
    "\n",
    "Neural Network model for a quick Head Pose estimation, using just facial points as input. The model was made for real-time control of a Pan-Tilt camera using face movements as the control signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies, set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(14)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Dropout, Activation, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers \n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 61)\n"
     ]
    }
   ],
   "source": [
    "dfCenter = pd.read_csv('datasets/face_center.csv')\n",
    "#dfCenter2 = pd.read_csv('datasets/face_center2.csv')\n",
    "#dfCenter3 = pd.read_csv('datasets/face_center3.csv')\n",
    "#dfCenter = dfCenter.append(dfCenter2, ignore_index = True).append(dfCenter3, ignore_index = True)\n",
    "\n",
    "dfRight = pd.read_csv('datasets/face_right.csv')\n",
    "#dfRight2 = pd.read_csv('datasets/face_right2.csv')\n",
    "#dfRight3 = pd.read_csv('datasets/face_right3.csv')\n",
    "#dfRight4 = pd.read_csv('datasets/face_right4.csv')\n",
    "#dfRight = dfRight.append(dfRight2, ignore_index = True).append(dfRight3, ignore_index = True).append(dfRight4, ignore_index = True)\n",
    "\n",
    "dfLeft = pd.read_csv('datasets/face_left.csv')\n",
    "#dfLeft2 = pd.read_csv('datasets/face_left2.csv')\n",
    "#dfLeft3 = pd.read_csv('datasets/face_left3.csv')\n",
    "#dfLeft4 = pd.read_csv('datasets/face_left4.csv')\n",
    "#dfLeft5 = pd.read_csv('datasets/face_left5.csv')\n",
    "#dfLeft = dfLeft.append(dfLeft2, ignore_index = True).append(dfLeft3, ignore_index = True).append(dfLeft4, ignore_index = True).append(dfLeft5, ignore_index = True)\n",
    "\n",
    "dfUp = pd.read_csv('datasets/face_up.csv')\n",
    "dfDown = pd.read_csv('datasets/face_down.csv')\n",
    "dfUpRight = pd.read_csv('datasets/face_up-right.csv')\n",
    "dfUpLeft = pd.read_csv('datasets/face_up-left.csv')\n",
    "dfDownRight = pd.read_csv('datasets/face_down-right.csv')\n",
    "\n",
    "dfDownLeft = pd.read_csv('datasets/face_down-left.csv')\n",
    "#dfDownLeft2 = pd.read_csv('datasets/face_down-left2.csv')\n",
    "#dfDownLeft3 = pd.read_csv('datasets/face_down-left3.csv')\n",
    "#dfDownLeft = dfDownLeft.append(dfDownLeft2, ignore_index = True).append(dfDownLeft3, ignore_index = True)\n",
    "\n",
    "columns = list(dfCenter)\n",
    "\n",
    "dfCenter['RESULT'] = 0\n",
    "dfRight['RESULT'] = 1\n",
    "dfLeft['RESULT'] = 2\n",
    "dfUp['RESULT'] = 3\n",
    "dfDown['RESULT'] = 4\n",
    "dfUpRight['RESULT'] = 5\n",
    "dfUpLeft['RESULT'] = 6\n",
    "dfDownRight['RESULT'] = 7\n",
    "dfDownLeft['RESULT'] = 8\n",
    "\n",
    "\n",
    "df = dfCenter.append(dfRight, ignore_index=True).append(dfLeft, ignore_index = True)\n",
    "df = df.append(dfUp, ignore_index = True).append(dfDown, ignore_index = True)\n",
    "df = df.append(dfUpRight, ignore_index = True).append(dfUpLeft, ignore_index = True)\n",
    "df = df.append(dfDownRight, ignore_index = True).append(dfDownLeft, ignore_index = True)\n",
    "\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4495</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.920769</td>\n",
       "      <td>0.897440</td>\n",
       "      <td>0.898442</td>\n",
       "      <td>0.871278</td>\n",
       "      <td>0.825369</td>\n",
       "      <td>0.782357</td>\n",
       "      <td>0.774431</td>\n",
       "      <td>0.801830</td>\n",
       "      <td>0.801830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324651</td>\n",
       "      <td>0.386135</td>\n",
       "      <td>0.455754</td>\n",
       "      <td>0.507020</td>\n",
       "      <td>0.480467</td>\n",
       "      <td>0.436155</td>\n",
       "      <td>0.374303</td>\n",
       "      <td>0.321068</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.907256</td>\n",
       "      <td>0.874157</td>\n",
       "      <td>0.860561</td>\n",
       "      <td>0.834543</td>\n",
       "      <td>0.783226</td>\n",
       "      <td>0.738433</td>\n",
       "      <td>0.735392</td>\n",
       "      <td>0.756263</td>\n",
       "      <td>0.768022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310963</td>\n",
       "      <td>0.362447</td>\n",
       "      <td>0.430281</td>\n",
       "      <td>0.508652</td>\n",
       "      <td>0.476326</td>\n",
       "      <td>0.413510</td>\n",
       "      <td>0.356212</td>\n",
       "      <td>0.307531</td>\n",
       "      <td>0.248106</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.906459</td>\n",
       "      <td>0.865125</td>\n",
       "      <td>0.851669</td>\n",
       "      <td>0.825920</td>\n",
       "      <td>0.775133</td>\n",
       "      <td>0.730803</td>\n",
       "      <td>0.734114</td>\n",
       "      <td>0.745201</td>\n",
       "      <td>0.760087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.328798</td>\n",
       "      <td>0.377528</td>\n",
       "      <td>0.434693</td>\n",
       "      <td>0.490143</td>\n",
       "      <td>0.477007</td>\n",
       "      <td>0.427999</td>\n",
       "      <td>0.372601</td>\n",
       "      <td>0.319534</td>\n",
       "      <td>0.250663</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.909009</td>\n",
       "      <td>0.874791</td>\n",
       "      <td>0.869813</td>\n",
       "      <td>0.832541</td>\n",
       "      <td>0.786036</td>\n",
       "      <td>0.757910</td>\n",
       "      <td>0.736437</td>\n",
       "      <td>0.758546</td>\n",
       "      <td>0.776774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320208</td>\n",
       "      <td>0.384563</td>\n",
       "      <td>0.451509</td>\n",
       "      <td>0.517020</td>\n",
       "      <td>0.493626</td>\n",
       "      <td>0.442059</td>\n",
       "      <td>0.380781</td>\n",
       "      <td>0.326180</td>\n",
       "      <td>0.260370</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4499</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.902666</td>\n",
       "      <td>0.876755</td>\n",
       "      <td>0.866617</td>\n",
       "      <td>0.835005</td>\n",
       "      <td>0.780461</td>\n",
       "      <td>0.747263</td>\n",
       "      <td>0.744515</td>\n",
       "      <td>0.774200</td>\n",
       "      <td>0.790083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362850</td>\n",
       "      <td>0.418881</td>\n",
       "      <td>0.486761</td>\n",
       "      <td>0.522545</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.437134</td>\n",
       "      <td>0.369495</td>\n",
       "      <td>0.307855</td>\n",
       "      <td>0.233031</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6  \\\n",
       "4495  1.0  0.920769  0.897440  0.898442  0.871278  0.825369  0.782357   \n",
       "4496  1.0  0.907256  0.874157  0.860561  0.834543  0.783226  0.738433   \n",
       "4497  1.0  0.906459  0.865125  0.851669  0.825920  0.775133  0.730803   \n",
       "4498  1.0  0.909009  0.874791  0.869813  0.832541  0.786036  0.757910   \n",
       "4499  1.0  0.902666  0.876755  0.866617  0.835005  0.780461  0.747263   \n",
       "\n",
       "             7         8         9  ...        51        52        53  \\\n",
       "4495  0.774431  0.801830  0.801830  ...  0.324651  0.386135  0.455754   \n",
       "4496  0.735392  0.756263  0.768022  ...  0.310963  0.362447  0.430281   \n",
       "4497  0.734114  0.745201  0.760087  ...  0.328798  0.377528  0.434693   \n",
       "4498  0.736437  0.758546  0.776774  ...  0.320208  0.384563  0.451509   \n",
       "4499  0.744515  0.774200  0.790083  ...  0.362850  0.418881  0.486761   \n",
       "\n",
       "            54        55        56        57        58        59  RESULT  \n",
       "4495  0.507020  0.480467  0.436155  0.374303  0.321068  0.265400       8  \n",
       "4496  0.508652  0.476326  0.413510  0.356212  0.307531  0.248106       8  \n",
       "4497  0.490143  0.477007  0.427999  0.372601  0.319534  0.250663       8  \n",
       "4498  0.517020  0.493626  0.442059  0.380781  0.326180  0.260370       8  \n",
       "4499  0.522545  0.488600  0.437134  0.369495  0.307855  0.233031       8  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input data and desired output, and then split training and test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = df[columns]\n",
    "y = df['RESULT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=14)\n",
    "\n",
    "c = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "\n",
    "n_classes = 9\n",
    "#one hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print (y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for i in range(1,X_train.shape[0]+1):\n",
    "    X.append(X_train[0:i].tolist()[0])\n",
    "len(X)\n",
    "\n",
    "Y = []\n",
    "for i in range(1,y_train.shape[0]+1):\n",
    "    Y.append(y_train[0:i].tolist()[0])\n",
    "len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_train).astype('float32')\n",
    "Y = np.array(y_train)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 51, 100)           1100      \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 51, 32)            3232      \n",
      "_________________________________________________________________\n",
      "batch_normalization_111 (Bat (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 51, 32)            1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_112 (Bat (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 51, 32)            1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_113 (Bat (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 51, 32)            1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_114 (Bat (None, 51, 32)            128       \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 51, 32)            0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 51, 9)             297       \n",
      "=================================================================\n",
      "Total params: 8,309\n",
      "Trainable params: 8,053\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 216000 into shape (128,1,60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-0811ef304da5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;31m# for layers in range(1, 5):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# X_new = array([[1.0,0.8634537263852682,0.7550683797983376,0.6766083980311693,0.6105539851678169,0.5704414015790741,0.5753162861652857,0.6279255072837533,0.634317188327362,0.6149428731822305,0.5660729283392674,0.5491935638206207,0.5535083874348202,0.6083476675122917,0.6882788400699552,0.7915827354996343,0.9179179909700335,0.8650096079496821,0.8086468979375749,0.695752227878763,0.5959801903225727,0.4942783927093914,0.5101372039962554,0.6191336186419911,0.7278660554122794,0.8342086149396643,0.880534685421328,0.3621523485241818,0.19189191551595036,0.04548274598178804,0.15016195917834194,0.19350222555566068,0.18193098392715215,0.2176528799919824,0.22741372990894018,0.24745289125103817,0.6512138184336927,0.6156153095484503,0.5280701549410947,0.4118637820051627,0.4516324456341951,0.5495701107032686,0.4269083321253682,0.5551876683829843,0.6408065356530825,0.6761496285820855,0.5753162861652857,0.4781099874671581,0.35726400214981907,0.30340775880150395,0.27926554184691915,0.30238330649415557,0.28657739482928707,0.3232156388438138,0.37643670446703803,0.40604656199615247,0.43743904356956603,0.4314872146239643,0.4259380846616632,0.39885023003525083\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-109-0811ef304da5>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, batch_size, epochs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 216000 into shape (128,1,60)"
     ]
    }
   ],
   "source": [
    "def create_dense(layer_sizes):\n",
    "    model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(64, kernel_size = 3, activation='relu', input_shape=(60,1)))\n",
    "# model.add(Flatten())\n",
    "#     model.add(Dense(layer_sizes[0], activation='relu', input_shape=(60,)))\n",
    "    \n",
    "#     model.add(Conv2D(32, (8,8),strides = (4,4), padding = 'same', input_shape = (60,1,1), activation = 'relu'))\n",
    "    model.add(Conv1D(100, 10, activation='relu', input_shape=(60,1)))\n",
    "\n",
    "#     model.add(Activation('relu'))\n",
    "\n",
    "    for s in layer_sizes[1:]:\n",
    "        model.add(Dense(units = s, activation = 'relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "    #model.add(Dense(128, activation='relu', input_shape=(60,)))\n",
    "    #model.add(BatchNormalization())\n",
    "\n",
    "    #model.add(Dense(256, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.5))\n",
    "\n",
    "    #model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Conv1D(100, 10,activation='relu'))\n",
    "\n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))\n",
    "def evaluate(model, batch_size=128, epochs=20):\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])\n",
    "    \n",
    "    X = np.array(X_train).astype('float32')\n",
    "    Y = np.array(y_train).astype('float32')\n",
    "    X = X.reshape(128,1,60)\n",
    "    Y = Y.reshape(128,1,60)\n",
    "    history = model.fit(X, Y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "#     X_new = X_train.tolist()\n",
    "#     Y_new = y_train.tolist()\n",
    "    \n",
    "    \n",
    "#     model.train_on_batch(X_train, y_train)\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['training', 'validation'], loc='best')\n",
    "# plt.show()\n",
    "\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')\n",
    "\n",
    "# for layers in range(1, 5):\n",
    "model = create_dense([32] * 5)\n",
    "evaluate(model)\n",
    "\n",
    "# X_new = array([[1.0,0.8634537263852682,0.7550683797983376,0.6766083980311693,0.6105539851678169,0.5704414015790741,0.5753162861652857,0.6279255072837533,0.634317188327362,0.6149428731822305,0.5660729283392674,0.5491935638206207,0.5535083874348202,0.6083476675122917,0.6882788400699552,0.7915827354996343,0.9179179909700335,0.8650096079496821,0.8086468979375749,0.695752227878763,0.5959801903225727,0.4942783927093914,0.5101372039962554,0.6191336186419911,0.7278660554122794,0.8342086149396643,0.880534685421328,0.3621523485241818,0.19189191551595036,0.04548274598178804,0.15016195917834194,0.19350222555566068,0.18193098392715215,0.2176528799919824,0.22741372990894018,0.24745289125103817,0.6512138184336927,0.6156153095484503,0.5280701549410947,0.4118637820051627,0.4516324456341951,0.5495701107032686,0.4269083321253682,0.5551876683829843,0.6408065356530825,0.6761496285820855,0.5753162861652857,0.4781099874671581,0.35726400214981907,0.30340775880150395,0.27926554184691915,0.30238330649415557,0.28657739482928707,0.3232156388438138,0.37643670446703803,0.40604656199615247,0.43743904356956603,0.4314872146239643,0.4259380846616632,0.39885023003525083\n",
    "\n",
    "# ]])\n",
    "# Y_new = model.predict_classes(X_new)\n",
    "# print(\"X=%s, Predicted=%s\" % (X_new[0], Y_new[0]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))\n",
    "def evaluate(model, batch_size=128, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['training', 'validation'], loc='best')\n",
    "# plt.show()\n",
    "\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 51, 100)           1100      \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 51, 9)             909       \n",
      "=================================================================\n",
      "Total params: 2,009\n",
      "Trainable params: 2,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_3_input to have 3 dimensions, but got array with shape (3600, 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-9d6b04406760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model.save('model/model_9_positions.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-952b9bc89504>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, batch_size, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.00125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepgaze/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepgaze/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepgaze/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv1d_3_input to have 3 dimensions, but got array with shape (3600, 60)"
     ]
    }
   ],
   "source": [
    "for layers in range(1, 5):\n",
    "    model = create_dense([32] * layers)\n",
    "    evaluate(model)\n",
    "\n",
    "# model.save('model/model_9_positions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
