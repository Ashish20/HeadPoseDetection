{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Head poses Model Training\n",
    "\n",
    "Neural Network model for a quick Head Pose estimation, using just facial points as input. The model was made for real-time control of a Pan-Tilt camera using face movements as the control signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies, set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(14)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Dropout, Activation, Conv2D, MaxPooling2D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers \n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 61)\n"
     ]
    }
   ],
   "source": [
    "dfCenter = pd.read_csv('datasets/face_center.csv')\n",
    "dfCenter2 = pd.read_csv('datasets/face_center2.csv')\n",
    "dfCenter = dfCenter.append(dfCenter2, ignore_index = True)\n",
    "\n",
    "dfRight = pd.read_csv('datasets/face_right.csv')\n",
    "dfRight2 = pd.read_csv('datasets/face_right2.csv')\n",
    "dfRight = dfRight.append(dfRight2, ignore_index = True)\n",
    "\n",
    "dfLeft = pd.read_csv('datasets/face_left.csv')\n",
    "dfLeft2 = pd.read_csv('datasets/face_left2.csv')\n",
    "dfLeft = dfLeft.append(dfLeft2, ignore_index = True)\n",
    "\n",
    "dfUp = pd.read_csv('datasets/face_up.csv')\n",
    "dfUp2 = pd.read_csv('datasets/face_up2.csv')\n",
    "dfUp = dfUp.append(dfUp2, ignore_index = True)\n",
    "\n",
    "dfDown = pd.read_csv('datasets/face_down.csv')\n",
    "dfDown2 = pd.read_csv('datasets/face_down2.csv')\n",
    "dfDown = dfDown.append(dfDown2, ignore_index = True)\n",
    "\n",
    "dfUpRight = pd.read_csv('datasets/face_up_right.csv')\n",
    "dfUpRight2 = pd.read_csv('datasets/face_up_right2.csv')\n",
    "dfUpRight = dfUpRight.append(dfUpRight2, ignore_index = True)\n",
    "\n",
    "dfUpLeft = pd.read_csv('datasets/face_up_left.csv')\n",
    "dfUpLeft2 = pd.read_csv('datasets/face_up_left2.csv')\n",
    "dfUpLeft = dfUpLeft.append(dfUpLeft2, ignore_index = True)\n",
    "\n",
    "dfDownRight = pd.read_csv('datasets/face_down_right.csv')\n",
    "dfDownRight2 = pd.read_csv('datasets/face_down_right2.csv')\n",
    "dfDownRight = dfDownRight.append(dfDownRight2, ignore_index = True)\n",
    "\n",
    "dfDownLeft = pd.read_csv('datasets/face_down_left.csv')\n",
    "dfDownLeft2 = pd.read_csv('datasets/face_down_left2.csv')\n",
    "dfDownLeft = dfDownLeft.append(dfDownLeft2, ignore_index = True)\n",
    "\n",
    "columns = list(dfCenter)\n",
    "\n",
    "dfCenter['RESULT'] = 0\n",
    "dfRight['RESULT'] = 1\n",
    "dfLeft['RESULT'] = 2\n",
    "dfUp['RESULT'] = 3\n",
    "dfDown['RESULT'] = 4\n",
    "dfUpRight['RESULT'] = 5\n",
    "dfUpLeft['RESULT'] = 6\n",
    "dfDownRight['RESULT'] = 7\n",
    "dfDownLeft['RESULT'] = 8\n",
    "\n",
    "\n",
    "df = dfCenter.append(dfRight, ignore_index=True).append(dfLeft, ignore_index = True)\n",
    "df = df.append(dfUp, ignore_index = True).append(dfDown, ignore_index = True)\n",
    "df = df.append(dfUpRight, ignore_index = True).append(dfUpLeft, ignore_index = True)\n",
    "df = df.append(dfDownRight, ignore_index = True).append(dfDownLeft, ignore_index = True)\n",
    "\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.870639</td>\n",
       "      <td>0.778903</td>\n",
       "      <td>0.725278</td>\n",
       "      <td>0.680233</td>\n",
       "      <td>0.661416</td>\n",
       "      <td>0.679687</td>\n",
       "      <td>0.725736</td>\n",
       "      <td>0.733129</td>\n",
       "      <td>0.697956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440451</td>\n",
       "      <td>0.461847</td>\n",
       "      <td>0.483469</td>\n",
       "      <td>0.492717</td>\n",
       "      <td>0.535039</td>\n",
       "      <td>0.545349</td>\n",
       "      <td>0.529865</td>\n",
       "      <td>0.501872</td>\n",
       "      <td>0.437781</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.873671</td>\n",
       "      <td>0.781486</td>\n",
       "      <td>0.735074</td>\n",
       "      <td>0.683443</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.673143</td>\n",
       "      <td>0.724177</td>\n",
       "      <td>0.729398</td>\n",
       "      <td>0.696364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>0.481957</td>\n",
       "      <td>0.495796</td>\n",
       "      <td>0.492139</td>\n",
       "      <td>0.528186</td>\n",
       "      <td>0.541326</td>\n",
       "      <td>0.529552</td>\n",
       "      <td>0.497978</td>\n",
       "      <td>0.431634</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.877431</td>\n",
       "      <td>0.790890</td>\n",
       "      <td>0.744683</td>\n",
       "      <td>0.692465</td>\n",
       "      <td>0.664408</td>\n",
       "      <td>0.677805</td>\n",
       "      <td>0.718668</td>\n",
       "      <td>0.727266</td>\n",
       "      <td>0.696576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448371</td>\n",
       "      <td>0.470152</td>\n",
       "      <td>0.488073</td>\n",
       "      <td>0.494257</td>\n",
       "      <td>0.521760</td>\n",
       "      <td>0.529427</td>\n",
       "      <td>0.515435</td>\n",
       "      <td>0.493970</td>\n",
       "      <td>0.433165</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8998</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881703</td>\n",
       "      <td>0.792698</td>\n",
       "      <td>0.741344</td>\n",
       "      <td>0.697454</td>\n",
       "      <td>0.673473</td>\n",
       "      <td>0.686590</td>\n",
       "      <td>0.721158</td>\n",
       "      <td>0.718938</td>\n",
       "      <td>0.687107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.426923</td>\n",
       "      <td>0.447417</td>\n",
       "      <td>0.465064</td>\n",
       "      <td>0.479192</td>\n",
       "      <td>0.519957</td>\n",
       "      <td>0.540319</td>\n",
       "      <td>0.528465</td>\n",
       "      <td>0.506383</td>\n",
       "      <td>0.439765</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.881703</td>\n",
       "      <td>0.794662</td>\n",
       "      <td>0.747706</td>\n",
       "      <td>0.701630</td>\n",
       "      <td>0.679918</td>\n",
       "      <td>0.693795</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.732642</td>\n",
       "      <td>0.692457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448210</td>\n",
       "      <td>0.467434</td>\n",
       "      <td>0.485004</td>\n",
       "      <td>0.482802</td>\n",
       "      <td>0.528204</td>\n",
       "      <td>0.543669</td>\n",
       "      <td>0.532557</td>\n",
       "      <td>0.512542</td>\n",
       "      <td>0.446091</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6  \\\n",
       "8995  1.0  0.870639  0.778903  0.725278  0.680233  0.661416  0.679687   \n",
       "8996  1.0  0.873671  0.781486  0.735074  0.683443  0.655249  0.673143   \n",
       "8997  1.0  0.877431  0.790890  0.744683  0.692465  0.664408  0.677805   \n",
       "8998  1.0  0.881703  0.792698  0.741344  0.697454  0.673473  0.686590   \n",
       "8999  1.0  0.881703  0.794662  0.747706  0.701630  0.679918  0.693795   \n",
       "\n",
       "             7         8         9  ...        51        52        53  \\\n",
       "8995  0.725736  0.733129  0.697956  ...  0.440451  0.461847  0.483469   \n",
       "8996  0.724177  0.729398  0.696364  ...  0.465730  0.481957  0.495796   \n",
       "8997  0.718668  0.727266  0.696576  ...  0.448371  0.470152  0.488073   \n",
       "8998  0.721158  0.718938  0.687107  ...  0.426923  0.447417  0.465064   \n",
       "8999  0.731132  0.732642  0.692457  ...  0.448210  0.467434  0.485004   \n",
       "\n",
       "            54        55        56        57        58        59  RESULT  \n",
       "8995  0.492717  0.535039  0.545349  0.529865  0.501872  0.437781       8  \n",
       "8996  0.492139  0.528186  0.541326  0.529552  0.497978  0.431634       8  \n",
       "8997  0.494257  0.521760  0.529427  0.515435  0.493970  0.433165       8  \n",
       "8998  0.479192  0.519957  0.540319  0.528465  0.506383  0.439765       8  \n",
       "8999  0.482802  0.528204  0.543669  0.532557  0.512542  0.446091       8  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 61)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input data and desired output, and then split training and test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = df[columns]\n",
    "y = df['RESULT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=14)\n",
    "\n",
    "c = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "\n",
    "n_classes = 9\n",
    "#one hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print (y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_np = X_train.values \n",
    "Y_train_np = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(X_train).astype('float32')\n",
    "Y = np.array(y_train)\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 60)\n",
      "(1800, 9)\n",
      "(7200, 60, 1)\n",
      "(1800, 60, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7200, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "X_train_np = np.expand_dims(X_train_np, axis=2)\n",
    "print(X_train_np.shape)\n",
    "X_test = np.expand_dims(X_test, axis=2)\n",
    "print(X_test.shape)\n",
    "#Y_train_np = np.expand_dims(Y_train_np, axis=2)\n",
    "Y_train_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dense(layer_sizes):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(32, 3, padding ='same', input_shape=(60,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(32, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    \n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D(64, 3, padding ='same'))\n",
    "    model.add(BatchNormalization())\n",
    "  \n",
    "    model.add(GlobalAveragePooling1D())\n",
    "  \n",
    "    model.add(Dense(128, activation='elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(128, activation = 'elu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(9, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=SGD(lr=0.00125),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def evaluate(model, batch_size=128, epochs=50):\n",
    "    model.summary()\n",
    "    history = model.fit(X_train_np, Y_train_np, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['training', 'validation'], loc='best')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 60, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 60, 32)            3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 60, 32)            128       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 60, 64)            6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 60, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 64)            256       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 73,769\n",
      "Trainable params: 73,129\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/50\n",
      "7200/7200 [==============================] - 26s 4ms/step - loss: 2.0945 - acc: 0.2774 - val_loss: 1.9889 - val_acc: 0.2950\n",
      "Epoch 2/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.9240 - acc: 0.4482 - val_loss: 1.8524 - val_acc: 0.4100\n",
      "Epoch 3/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 1.8005 - acc: 0.5021 - val_loss: 1.7395 - val_acc: 0.4272\n",
      "Epoch 4/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.6896 - acc: 0.5574 - val_loss: 1.6457 - val_acc: 0.4483\n",
      "Epoch 5/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.5981 - acc: 0.6090 - val_loss: 1.5560 - val_acc: 0.6383\n",
      "Epoch 6/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.5093 - acc: 0.6469 - val_loss: 1.4669 - val_acc: 0.7461\n",
      "Epoch 7/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.4253 - acc: 0.6839 - val_loss: 1.3969 - val_acc: 0.7789\n",
      "Epoch 8/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.3507 - acc: 0.7169 - val_loss: 1.3175 - val_acc: 0.7950\n",
      "Epoch 9/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.2795 - acc: 0.7372 - val_loss: 1.2495 - val_acc: 0.8117\n",
      "Epoch 10/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.2177 - acc: 0.7539 - val_loss: 1.1879 - val_acc: 0.8206\n",
      "Epoch 11/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.1496 - acc: 0.7818 - val_loss: 1.1154 - val_acc: 0.8322\n",
      "Epoch 12/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.0896 - acc: 0.8076 - val_loss: 1.0546 - val_acc: 0.8378\n",
      "Epoch 13/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 1.0406 - acc: 0.8110 - val_loss: 0.9975 - val_acc: 0.8433\n",
      "Epoch 14/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.9874 - acc: 0.8300 - val_loss: 0.9440 - val_acc: 0.8483\n",
      "Epoch 15/50\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.9417 - acc: 0.8340 - val_loss: 0.8920 - val_acc: 0.8606\n",
      "Epoch 16/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.8996 - acc: 0.8414 - val_loss: 0.8493 - val_acc: 0.8706\n",
      "Epoch 17/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.8573 - acc: 0.8471 - val_loss: 0.8121 - val_acc: 0.8722\n",
      "Epoch 18/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.8173 - acc: 0.8610 - val_loss: 0.7712 - val_acc: 0.8867\n",
      "Epoch 19/50\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.7880 - acc: 0.8636 - val_loss: 0.7391 - val_acc: 0.8906\n",
      "Epoch 20/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.7529 - acc: 0.8672 - val_loss: 0.7085 - val_acc: 0.8878\n",
      "Epoch 21/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.7266 - acc: 0.8738 - val_loss: 0.6756 - val_acc: 0.8944\n",
      "Epoch 22/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.6943 - acc: 0.8779 - val_loss: 0.6544 - val_acc: 0.8944\n",
      "Epoch 23/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.6757 - acc: 0.8781 - val_loss: 0.6230 - val_acc: 0.9028\n",
      "Epoch 24/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.6462 - acc: 0.8851 - val_loss: 0.6051 - val_acc: 0.8994\n",
      "Epoch 25/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.6267 - acc: 0.8889 - val_loss: 0.5806 - val_acc: 0.9044\n",
      "Epoch 26/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.6035 - acc: 0.8903 - val_loss: 0.5611 - val_acc: 0.9000\n",
      "Epoch 27/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5909 - acc: 0.8943 - val_loss: 0.5434 - val_acc: 0.9022\n",
      "Epoch 28/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5738 - acc: 0.8911 - val_loss: 0.5268 - val_acc: 0.9056\n",
      "Epoch 29/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5589 - acc: 0.8925 - val_loss: 0.5123 - val_acc: 0.9072\n",
      "Epoch 30/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5419 - acc: 0.8992 - val_loss: 0.4962 - val_acc: 0.9100\n",
      "Epoch 31/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5290 - acc: 0.8993 - val_loss: 0.4865 - val_acc: 0.9100\n",
      "Epoch 32/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.5154 - acc: 0.8992 - val_loss: 0.4693 - val_acc: 0.9106\n",
      "Epoch 33/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4998 - acc: 0.9035 - val_loss: 0.4582 - val_acc: 0.9139\n",
      "Epoch 34/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4913 - acc: 0.9031 - val_loss: 0.4470 - val_acc: 0.9144\n",
      "Epoch 35/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4726 - acc: 0.9047 - val_loss: 0.4346 - val_acc: 0.9172\n",
      "Epoch 36/50\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.4607 - acc: 0.9099 - val_loss: 0.4283 - val_acc: 0.9161\n",
      "Epoch 37/50\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.4569 - acc: 0.9094 - val_loss: 0.4211 - val_acc: 0.9144\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4484 - acc: 0.9087 - val_loss: 0.4077 - val_acc: 0.9183\n",
      "Epoch 39/50\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.4360 - acc: 0.9114 - val_loss: 0.3989 - val_acc: 0.9233\n",
      "Epoch 40/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.4275 - acc: 0.9165 - val_loss: 0.3949 - val_acc: 0.9211\n",
      "Epoch 41/50\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.4171 - acc: 0.9190 - val_loss: 0.3787 - val_acc: 0.9278\n",
      "Epoch 42/50\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.4081 - acc: 0.9185 - val_loss: 0.3737 - val_acc: 0.9222\n",
      "Epoch 43/50\n",
      "7200/7200 [==============================] - 18s 3ms/step - loss: 0.3993 - acc: 0.9157 - val_loss: 0.3628 - val_acc: 0.9250\n",
      "Epoch 44/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3918 - acc: 0.9201 - val_loss: 0.3588 - val_acc: 0.9250\n",
      "Epoch 45/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3826 - acc: 0.9246 - val_loss: 0.3461 - val_acc: 0.9344\n",
      "Epoch 46/50\n",
      "7200/7200 [==============================] - 18s 2ms/step - loss: 0.3790 - acc: 0.9225 - val_loss: 0.3409 - val_acc: 0.9283\n",
      "Epoch 47/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3672 - acc: 0.9263 - val_loss: 0.3345 - val_acc: 0.9272\n",
      "Epoch 48/50\n",
      "7200/7200 [==============================] - 20s 3ms/step - loss: 0.3630 - acc: 0.9282 - val_loss: 0.3277 - val_acc: 0.9289\n",
      "Epoch 49/50\n",
      "7200/7200 [==============================] - 19s 3ms/step - loss: 0.3544 - acc: 0.9268 - val_loss: 0.3181 - val_acc: 0.9356\n",
      "Epoch 50/50\n",
      "7200/7200 [==============================] - 17s 2ms/step - loss: 0.3484 - acc: 0.9283 - val_loss: 0.3106 - val_acc: 0.9367\n",
      "Test loss: 0.311\n",
      "Test accuracy: 0.937\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for layers in range(1, 5):\n",
    "model = create_dense([32] * 5)\n",
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))\n",
    "def evaluate(model, batch_size=128, epochs=5):\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "    loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "# plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['training', 'validation'], loc='best')\n",
    "# plt.show()\n",
    "\n",
    "    print(f'Test loss: {loss:.3}')\n",
    "    print(f'Test accuracy: {accuracy:.3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in range(1, 5):\n",
    "    model = create_dense([32] * layers)\n",
    "    evaluate(model)\n",
    "\n",
    "# model.save('model/model_9_positions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
