{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9 Head poses Model Training\n",
    "\n",
    "Neural Network model for a quick Head Pose estimation, using just facial points as input. The model was made for real-time control of a Pan-Tilt camera using face movements as the control signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies, set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(14)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Dropout \n",
    "from keras.layers.normalization import BatchNormalization \n",
    "from keras import regularizers \n",
    "from keras.layers.convolutional import Conv1D\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 61)\n"
     ]
    }
   ],
   "source": [
    "dfCenter = pd.read_csv('datasets/face_center.csv')\n",
    "dfCenter2 = pd.read_csv('datasets/face_center2.csv')\n",
    "dfCenter = dfCenter.append(dfCenter2, ignore_index = True)\n",
    "\n",
    "dfRight = pd.read_csv('datasets/face_right.csv')\n",
    "dfRight2 = pd.read_csv('datasets/face_right2.csv')\n",
    "dfRight = dfRight.append(dfRight2, ignore_index = True)\n",
    "\n",
    "dfLeft = pd.read_csv('datasets/face_left.csv')\n",
    "dfLeft2 = pd.read_csv('datasets/face_left2.csv')\n",
    "dfLeft = dfLeft.append(dfLeft2, ignore_index = True)\n",
    "\n",
    "dfUp = pd.read_csv('datasets/face_up.csv')\n",
    "dfUp2 = pd.read_csv('datasets/face_up2.csv')\n",
    "dfUp = dfUp.append(dfUp2, ignore_index = True)\n",
    "\n",
    "dfDown = pd.read_csv('datasets/face_down.csv')\n",
    "dfDown2 = pd.read_csv('datasets/face_down2.csv')\n",
    "dfDown = dfDown.append(dfDown2, ignore_index = True)\n",
    "\n",
    "dfUpRight = pd.read_csv('datasets/face_up_right.csv')\n",
    "dfUpRight2 = pd.read_csv('datasets/face_up_right2.csv')\n",
    "dfUpRight = dfUpRight.append(dfUpRight2, ignore_index = True)\n",
    "\n",
    "dfUpLeft = pd.read_csv('datasets/face_up_left.csv')\n",
    "dfUpLeft2 = pd.read_csv('datasets/face_up_left2.csv')\n",
    "dfUpLeft = dfUpLeft.append(dfUpLeft2, ignore_index = True)\n",
    "\n",
    "dfDownRight = pd.read_csv('datasets/face_down_right.csv')\n",
    "dfDownRight2 = pd.read_csv('datasets/face_down_right2.csv')\n",
    "dfDownRight = dfDownRight.append(dfDownRight2, ignore_index = True)\n",
    "\n",
    "dfDownLeft = pd.read_csv('datasets/face_down_left.csv')\n",
    "dfDownLeft2 = pd.read_csv('datasets/face_down_left2.csv')\n",
    "dfDownLeft = dfDownLeft.append(dfDownLeft2, ignore_index = True)\n",
    "\n",
    "columns = list(dfCenter)\n",
    "\n",
    "dfCenter['RESULT'] = 0\n",
    "dfRight['RESULT'] = 1\n",
    "dfLeft['RESULT'] = 2\n",
    "dfUp['RESULT'] = 3\n",
    "dfDown['RESULT'] = 4\n",
    "dfUpRight['RESULT'] = 5\n",
    "dfUpLeft['RESULT'] = 6\n",
    "dfDownRight['RESULT'] = 7\n",
    "dfDownLeft['RESULT'] = 8\n",
    "\n",
    "\n",
    "df = dfCenter.append(dfRight, ignore_index=True).append(dfLeft, ignore_index = True)\n",
    "df = df.append(dfUp, ignore_index = True).append(dfDown, ignore_index = True)\n",
    "df = df.append(dfUpRight, ignore_index = True).append(dfUpLeft, ignore_index = True)\n",
    "df = df.append(dfDownRight, ignore_index = True).append(dfDownLeft, ignore_index = True)\n",
    "\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>RESULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858809</td>\n",
       "      <td>0.781256</td>\n",
       "      <td>0.746218</td>\n",
       "      <td>0.743311</td>\n",
       "      <td>0.764450</td>\n",
       "      <td>0.789241</td>\n",
       "      <td>0.796396</td>\n",
       "      <td>0.832012</td>\n",
       "      <td>0.838224</td>\n",
       "      <td>0.832147</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142489</td>\n",
       "      <td>0.159307</td>\n",
       "      <td>0.263332</td>\n",
       "      <td>0.415602</td>\n",
       "      <td>0.364507</td>\n",
       "      <td>0.341785</td>\n",
       "      <td>0.328761</td>\n",
       "      <td>0.325338</td>\n",
       "      <td>0.340034</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.867722</td>\n",
       "      <td>0.780481</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.718613</td>\n",
       "      <td>0.719886</td>\n",
       "      <td>0.732531</td>\n",
       "      <td>0.759472</td>\n",
       "      <td>0.798078</td>\n",
       "      <td>0.808493</td>\n",
       "      <td>0.801999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171308</td>\n",
       "      <td>0.194701</td>\n",
       "      <td>0.297484</td>\n",
       "      <td>0.429089</td>\n",
       "      <td>0.385692</td>\n",
       "      <td>0.368179</td>\n",
       "      <td>0.358008</td>\n",
       "      <td>0.349135</td>\n",
       "      <td>0.348292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.877703</td>\n",
       "      <td>0.797423</td>\n",
       "      <td>0.736385</td>\n",
       "      <td>0.729313</td>\n",
       "      <td>0.735067</td>\n",
       "      <td>0.746128</td>\n",
       "      <td>0.776003</td>\n",
       "      <td>0.811224</td>\n",
       "      <td>0.825969</td>\n",
       "      <td>0.815212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168584</td>\n",
       "      <td>0.191605</td>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.427896</td>\n",
       "      <td>0.381462</td>\n",
       "      <td>0.367352</td>\n",
       "      <td>0.360646</td>\n",
       "      <td>0.356262</td>\n",
       "      <td>0.358694</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.887809</td>\n",
       "      <td>0.795197</td>\n",
       "      <td>0.740729</td>\n",
       "      <td>0.723141</td>\n",
       "      <td>0.726975</td>\n",
       "      <td>0.736697</td>\n",
       "      <td>0.760959</td>\n",
       "      <td>0.805041</td>\n",
       "      <td>0.813587</td>\n",
       "      <td>0.811020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172387</td>\n",
       "      <td>0.202081</td>\n",
       "      <td>0.293441</td>\n",
       "      <td>0.425851</td>\n",
       "      <td>0.383749</td>\n",
       "      <td>0.367899</td>\n",
       "      <td>0.360264</td>\n",
       "      <td>0.352182</td>\n",
       "      <td>0.353588</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.896083</td>\n",
       "      <td>0.795655</td>\n",
       "      <td>0.732237</td>\n",
       "      <td>0.714301</td>\n",
       "      <td>0.714440</td>\n",
       "      <td>0.730608</td>\n",
       "      <td>0.760959</td>\n",
       "      <td>0.807052</td>\n",
       "      <td>0.813546</td>\n",
       "      <td>0.805041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169873</td>\n",
       "      <td>0.190620</td>\n",
       "      <td>0.287862</td>\n",
       "      <td>0.425851</td>\n",
       "      <td>0.372547</td>\n",
       "      <td>0.365462</td>\n",
       "      <td>0.359436</td>\n",
       "      <td>0.353214</td>\n",
       "      <td>0.346116</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.858809  0.781256  0.746218  0.743311  0.764450  0.789241  0.796396   \n",
       "1  0.867722  0.780481  0.736402  0.718613  0.719886  0.732531  0.759472   \n",
       "2  0.877703  0.797423  0.736385  0.729313  0.735067  0.746128  0.776003   \n",
       "3  0.887809  0.795197  0.740729  0.723141  0.726975  0.736697  0.760959   \n",
       "4  0.896083  0.795655  0.732237  0.714301  0.714440  0.730608  0.760959   \n",
       "\n",
       "          7         8         9  ...        51        52        53        54  \\\n",
       "0  0.832012  0.838224  0.832147  ...  0.142489  0.159307  0.263332  0.415602   \n",
       "1  0.798078  0.808493  0.801999  ...  0.171308  0.194701  0.297484  0.429089   \n",
       "2  0.811224  0.825969  0.815212  ...  0.168584  0.191605  0.289119  0.427896   \n",
       "3  0.805041  0.813587  0.811020  ...  0.172387  0.202081  0.293441  0.425851   \n",
       "4  0.807052  0.813546  0.805041  ...  0.169873  0.190620  0.287862  0.425851   \n",
       "\n",
       "         55        56        57        58        59  RESULT  \n",
       "0  0.364507  0.341785  0.328761  0.325338  0.340034       0  \n",
       "1  0.385692  0.368179  0.358008  0.349135  0.348292       0  \n",
       "2  0.381462  0.367352  0.360646  0.356262  0.358694       0  \n",
       "3  0.383749  0.367899  0.360264  0.352182  0.353588       0  \n",
       "4  0.372547  0.365462  0.359436  0.353214  0.346116       0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input data and desired output, and then split training and test observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = df[columns]\n",
    "y = df['RESULT']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=14)\n",
    "\n",
    "X_train = np.array(X_train).astype('float32')\n",
    "X_test = np.array(X_test).astype('float32')\n",
    "\n",
    "n_classes = 9\n",
    "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "\n",
    "print (y_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Neural Network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(64, kernel_size = 3, activation='relu', input_shape=(60,1)))\n",
    "# model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', input_shape=(60,)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               7808      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 76,425\n",
      "Trainable params: 75,657\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.00125), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7200 samples, validate on 1800 samples\n",
      "Epoch 1/70\n",
      "7200/7200 [==============================] - 7s 947us/step - loss: 1.6205 - acc: 0.4879 - val_loss: 0.3314 - val_acc: 0.9344\n",
      "Epoch 2/70\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.7989 - acc: 0.7417 - val_loss: 0.2597 - val_acc: 0.9039\n",
      "Epoch 3/70\n",
      "7200/7200 [==============================] - 3s 375us/step - loss: 0.6036 - acc: 0.8122 - val_loss: 0.2084 - val_acc: 0.9389\n",
      "Epoch 4/70\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.5054 - acc: 0.8436 - val_loss: 0.1862 - val_acc: 0.9472\n",
      "Epoch 5/70\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.4515 - acc: 0.8653 - val_loss: 0.1691 - val_acc: 0.9561\n",
      "Epoch 6/70\n",
      "7200/7200 [==============================] - 3s 379us/step - loss: 0.3969 - acc: 0.8822 - val_loss: 0.1678 - val_acc: 0.9550\n",
      "Epoch 7/70\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.3750 - acc: 0.8889 - val_loss: 0.1673 - val_acc: 0.9550\n",
      "Epoch 8/70\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.3604 - acc: 0.8968 - val_loss: 0.1481 - val_acc: 0.9611\n",
      "Epoch 9/70\n",
      "7200/7200 [==============================] - 3s 381us/step - loss: 0.3348 - acc: 0.9029 - val_loss: 0.1356 - val_acc: 0.9667\n",
      "Epoch 10/70\n",
      "7200/7200 [==============================] - 3s 378us/step - loss: 0.3174 - acc: 0.9087 - val_loss: 0.1335 - val_acc: 0.9667\n",
      "Epoch 11/70\n",
      "7200/7200 [==============================] - 3s 380us/step - loss: 0.2931 - acc: 0.9172 - val_loss: 0.1225 - val_acc: 0.9700\n",
      "Epoch 12/70\n",
      "7200/7200 [==============================] - 3s 469us/step - loss: 0.2897 - acc: 0.9193 - val_loss: 0.1313 - val_acc: 0.9672\n",
      "Epoch 13/70\n",
      "7200/7200 [==============================] - 3s 424us/step - loss: 0.2761 - acc: 0.9235 - val_loss: 0.1243 - val_acc: 0.9667\n",
      "Epoch 14/70\n",
      "7200/7200 [==============================] - 3s 382us/step - loss: 0.2457 - acc: 0.9315 - val_loss: 0.1120 - val_acc: 0.9733\n",
      "Epoch 15/70\n",
      "7200/7200 [==============================] - 3s 384us/step - loss: 0.2457 - acc: 0.9321 - val_loss: 0.1126 - val_acc: 0.9700\n",
      "Epoch 16/70\n",
      "7200/7200 [==============================] - 3s 456us/step - loss: 0.2482 - acc: 0.9332 - val_loss: 0.1126 - val_acc: 0.9700\n",
      "Epoch 17/70\n",
      "7200/7200 [==============================] - 3s 393us/step - loss: 0.2348 - acc: 0.9346 - val_loss: 0.1089 - val_acc: 0.9717\n",
      "Epoch 18/70\n",
      "7200/7200 [==============================] - 3s 429us/step - loss: 0.2233 - acc: 0.9369 - val_loss: 0.1091 - val_acc: 0.9700\n",
      "Epoch 19/70\n",
      "7200/7200 [==============================] - 3s 446us/step - loss: 0.2207 - acc: 0.9375 - val_loss: 0.1174 - val_acc: 0.9667\n",
      "Epoch 20/70\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.2113 - acc: 0.9382 - val_loss: 0.1011 - val_acc: 0.9722\n",
      "Epoch 21/70\n",
      "7200/7200 [==============================] - 3s 408us/step - loss: 0.2120 - acc: 0.9410 - val_loss: 0.0963 - val_acc: 0.9744\n",
      "Epoch 22/70\n",
      "7200/7200 [==============================] - 3s 383us/step - loss: 0.2091 - acc: 0.9418 - val_loss: 0.1271 - val_acc: 0.9633\n",
      "Epoch 23/70\n",
      "7200/7200 [==============================] - 3s 414us/step - loss: 0.2139 - acc: 0.9386 - val_loss: 0.1038 - val_acc: 0.9728\n",
      "Epoch 24/70\n",
      "7200/7200 [==============================] - 3s 404us/step - loss: 0.2026 - acc: 0.9444 - val_loss: 0.1045 - val_acc: 0.9689\n",
      "Epoch 25/70\n",
      "7200/7200 [==============================] - 3s 395us/step - loss: 0.1945 - acc: 0.9440 - val_loss: 0.0950 - val_acc: 0.9711\n",
      "Epoch 26/70\n",
      "7200/7200 [==============================] - 3s 419us/step - loss: 0.1884 - acc: 0.9468 - val_loss: 0.1020 - val_acc: 0.9722\n",
      "Epoch 27/70\n",
      "7200/7200 [==============================] - 3s 388us/step - loss: 0.1920 - acc: 0.9494 - val_loss: 0.0917 - val_acc: 0.9733\n",
      "Epoch 28/70\n",
      "7200/7200 [==============================] - 3s 405us/step - loss: 0.1936 - acc: 0.9464 - val_loss: 0.0910 - val_acc: 0.9722\n",
      "Epoch 29/70\n",
      "7200/7200 [==============================] - 4s 572us/step - loss: 0.1711 - acc: 0.9535 - val_loss: 0.0883 - val_acc: 0.9733\n",
      "Epoch 30/70\n",
      "7200/7200 [==============================] - 3s 391us/step - loss: 0.1760 - acc: 0.9501 - val_loss: 0.0823 - val_acc: 0.9750\n",
      "Epoch 31/70\n",
      "7200/7200 [==============================] - 3s 383us/step - loss: 0.1826 - acc: 0.9551 - val_loss: 0.1105 - val_acc: 0.9656\n",
      "Epoch 32/70\n",
      "7200/7200 [==============================] - 3s 423us/step - loss: 0.1725 - acc: 0.9519 - val_loss: 0.0798 - val_acc: 0.9761\n",
      "Epoch 33/70\n",
      "7200/7200 [==============================] - 3s 393us/step - loss: 0.1762 - acc: 0.9531 - val_loss: 0.0873 - val_acc: 0.9717\n",
      "Epoch 34/70\n",
      "7200/7200 [==============================] - 3s 387us/step - loss: 0.1586 - acc: 0.9571 - val_loss: 0.0848 - val_acc: 0.9744\n",
      "Epoch 35/70\n",
      "7200/7200 [==============================] - 3s 394us/step - loss: 0.1612 - acc: 0.9540 - val_loss: 0.0854 - val_acc: 0.9739\n",
      "Epoch 36/70\n",
      "7200/7200 [==============================] - 3s 446us/step - loss: 0.1538 - acc: 0.9578 - val_loss: 0.0760 - val_acc: 0.9744\n",
      "Epoch 37/70\n",
      "7200/7200 [==============================] - 3s 430us/step - loss: 0.1611 - acc: 0.9547 - val_loss: 0.0775 - val_acc: 0.9761\n",
      "Epoch 38/70\n",
      "7200/7200 [==============================] - 3s 464us/step - loss: 0.1572 - acc: 0.9536 - val_loss: 0.0744 - val_acc: 0.9783\n",
      "Epoch 39/70\n",
      "7200/7200 [==============================] - 3s 435us/step - loss: 0.1497 - acc: 0.9579 - val_loss: 0.0690 - val_acc: 0.9767\n",
      "Epoch 40/70\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.1588 - acc: 0.9547 - val_loss: 0.0848 - val_acc: 0.9739\n",
      "Epoch 41/70\n",
      "7200/7200 [==============================] - 3s 366us/step - loss: 0.1523 - acc: 0.9567 - val_loss: 0.0721 - val_acc: 0.9767\n",
      "Epoch 42/70\n",
      "7200/7200 [==============================] - 3s 355us/step - loss: 0.1551 - acc: 0.9571 - val_loss: 0.0718 - val_acc: 0.9778\n",
      "Epoch 43/70\n",
      "7200/7200 [==============================] - 3s 372us/step - loss: 0.1635 - acc: 0.9529 - val_loss: 0.0880 - val_acc: 0.9683\n",
      "Epoch 44/70\n",
      "7200/7200 [==============================] - 3s 364us/step - loss: 0.1609 - acc: 0.9540 - val_loss: 0.0716 - val_acc: 0.9789\n",
      "Epoch 45/70\n",
      "7200/7200 [==============================] - 3s 402us/step - loss: 0.1414 - acc: 0.9599 - val_loss: 0.0727 - val_acc: 0.9778\n",
      "Epoch 46/70\n",
      "7200/7200 [==============================] - 3s 422us/step - loss: 0.1424 - acc: 0.9587 - val_loss: 0.0726 - val_acc: 0.9756\n",
      "Epoch 47/70\n",
      "7200/7200 [==============================] - 4s 512us/step - loss: 0.1487 - acc: 0.9569 - val_loss: 0.0787 - val_acc: 0.9744\n",
      "Epoch 48/70\n",
      "7200/7200 [==============================] - 3s 447us/step - loss: 0.1406 - acc: 0.9601 - val_loss: 0.0631 - val_acc: 0.9794\n",
      "Epoch 49/70\n",
      "7200/7200 [==============================] - 3s 404us/step - loss: 0.1430 - acc: 0.9589 - val_loss: 0.0681 - val_acc: 0.9783\n",
      "Epoch 50/70\n",
      "7200/7200 [==============================] - 3s 407us/step - loss: 0.1344 - acc: 0.9608 - val_loss: 0.0700 - val_acc: 0.9767\n",
      "Epoch 51/70\n",
      "7200/7200 [==============================] - 3s 432us/step - loss: 0.1343 - acc: 0.9597 - val_loss: 0.0669 - val_acc: 0.9789\n",
      "Epoch 52/70\n",
      "7200/7200 [==============================] - 3s 440us/step - loss: 0.1247 - acc: 0.9619 - val_loss: 0.0700 - val_acc: 0.9789\n",
      "Epoch 53/70\n",
      "7200/7200 [==============================] - 3s 418us/step - loss: 0.1316 - acc: 0.9600 - val_loss: 0.0611 - val_acc: 0.9800\n",
      "Epoch 54/70\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.1294 - acc: 0.9617 - val_loss: 0.0810 - val_acc: 0.9739\n",
      "Epoch 55/70\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.1305 - acc: 0.9619 - val_loss: 0.0619 - val_acc: 0.9789\n",
      "Epoch 56/70\n",
      "7200/7200 [==============================] - 3s 355us/step - loss: 0.1313 - acc: 0.9647 - val_loss: 0.0694 - val_acc: 0.9772\n",
      "Epoch 57/70\n",
      "7200/7200 [==============================] - 3s 360us/step - loss: 0.1371 - acc: 0.9599 - val_loss: 0.0630 - val_acc: 0.9772\n",
      "Epoch 58/70\n",
      "7200/7200 [==============================] - 3s 349us/step - loss: 0.1181 - acc: 0.9643 - val_loss: 0.0697 - val_acc: 0.9761\n",
      "Epoch 59/70\n",
      "7200/7200 [==============================] - 3s 373us/step - loss: 0.1248 - acc: 0.9646 - val_loss: 0.0589 - val_acc: 0.9778\n",
      "Epoch 60/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200/7200 [==============================] - 3s 351us/step - loss: 0.1218 - acc: 0.9664 - val_loss: 0.0590 - val_acc: 0.9817\n",
      "Epoch 61/70\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.1156 - acc: 0.9661 - val_loss: 0.0558 - val_acc: 0.9817\n",
      "Epoch 62/70\n",
      "7200/7200 [==============================] - 3s 348us/step - loss: 0.1327 - acc: 0.9632 - val_loss: 0.0645 - val_acc: 0.9833\n",
      "Epoch 63/70\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.1173 - acc: 0.9653 - val_loss: 0.0635 - val_acc: 0.9778\n",
      "Epoch 64/70\n",
      "7200/7200 [==============================] - 3s 349us/step - loss: 0.1184 - acc: 0.9639 - val_loss: 0.0508 - val_acc: 0.9828\n",
      "Epoch 65/70\n",
      "7200/7200 [==============================] - 3s 350us/step - loss: 0.1058 - acc: 0.9690 - val_loss: 0.0603 - val_acc: 0.9772\n",
      "Epoch 66/70\n",
      "7200/7200 [==============================] - 3s 349us/step - loss: 0.1109 - acc: 0.9674 - val_loss: 0.0833 - val_acc: 0.9722\n",
      "Epoch 67/70\n",
      "7200/7200 [==============================] - 3s 359us/step - loss: 0.1101 - acc: 0.9671 - val_loss: 0.0519 - val_acc: 0.9844\n",
      "Epoch 68/70\n",
      "7200/7200 [==============================] - 3s 356us/step - loss: 0.1151 - acc: 0.9690 - val_loss: 0.0541 - val_acc: 0.9822\n",
      "Epoch 69/70\n",
      "7200/7200 [==============================] - 3s 369us/step - loss: 0.1013 - acc: 0.9708 - val_loss: 0.0572 - val_acc: 0.9822\n",
      "Epoch 70/70\n",
      "7200/7200 [==============================] - 3s 353us/step - loss: 0.1146 - acc: 0.9674 - val_loss: 0.0543 - val_acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8lNXZ8PHflX0nIQsEAoQlrIJBEK0oda3gvlBFrRWeWlprq7a2j7Z93lZ92vfp89ba1tbWWqu1dUXqXlcUxQ0kLLLvawgkIWTfZjJz3j/OnWGSTJIRMsmEub6fz3wyc8+9XDNJznXuc+77HDHGoJRSSgFE9XUASimlwocmBaWUUj6aFJRSSvloUlBKKeWjSUEppZSPJgWllFI+mhRURBGRv4vIL4Jcd4+InB/qmJQKJ5oUlFJK+WhSUKofEpGYvo5BnZg0Kaiw4zTb/EhE1olIvYj8TUQGicgbIlIrIktEJMNv/ctEZKOIVInI+yIywe+9qSKy2tnuOSCh3bEuEZG1zrafiMiUIGO8WETWiEiNiOwXkXvavX+ms78q5/35zvJEEfmNiOwVkWoR+chZdraIFAf4Hs53nt8jIotF5EkRqQHmi8gMEfnUOcZBEfmjiMT5bT9JRN4RkSMiUioiPxGRwSLSICKZfutNE5FyEYkN5rOrE5smBRWurgYuAMYClwJvAD8BsrB/t7cBiMhY4BngDiAbeB14VUTinALyJeCfwEDgeWe/ONueAjwGfAvIBP4CvCIi8UHEVw98HUgHLgZuEZErnP0Od+L9gxNTIbDW2e5+YBpwhhPTfwLeIL+Ty4HFzjGfAjzA953v5EvAecB3nBhSgSXAm8AQYAzwrjHmEPA+cI3ffr8GPGuMcQcZhzqBaVJQ4eoPxphSY8wB4ENghTFmjTGmGXgRmOqsdy3wb2PMO06hdj+QiC10Twdigd8ZY9zGmMXASr9jfBP4izFmhTHGY4x5Amh2tuuSMeZ9Y8x6Y4zXGLMOm5i+7Lx9A7DEGPOMc9wKY8xaEYkC/gO43RhzwDnmJ85nCsanxpiXnGM2GmNWGWOWG2NajDF7sEmtNYZLgEPGmN8YY5qMMbXGmBXOe09gEwEiEg1ch02cSmlSUGGr1O95Y4DXKc7zIcDe1jeMMV5gPzDUee+AaTvq416/5yOAO53mlyoRqQKGOdt1SUROE5GlTrNLNfBtbI0dZx87A2yWhW2+CvReMPa3i2GsiLwmIoecJqX/G0QMAC8DE0VkFPZsrNoY89kxxqROMJoUVH9Xgi3cARARwRaIB4CDwFBnWavhfs/3A780xqT7PZKMMc8EcdyngVeAYcaYAcDDQOtx9gOjA2xzGGjq5L16IMnvc0Rjm578tR/S+M/AFqDAGJOGbV7rLgaMMU3AIuwZzY3oWYLyo0lB9XeLgItF5Dyno/RObBPQJ8CnQAtwm4jEiMhVwAy/bf8KfNup9YuIJDsdyKlBHDcVOGKMaRKRGcD1fu89BZwvItc4x80UkULnLOYx4AERGSIi0SLyJacPYxuQ4Bw/FvgvoLu+jVSgBqgTkfHALX7vvQYMFpE7RCReRFJF5DS/9/8BzAcuA54M4vOqCKFJQfVrxpit2PbxP2Br4pcClxpjXMYYF3AVtvCrxPY/vOC3bRG2X+GPzvs7nHWD8R3gPhGpBX6GTU6t+90HXIRNUEewncwnO2//EFiP7ds4AvwvEGWMqXb2+Sj2LKceaHM1UgA/xCajWmyCe84vhlps09ClwCFgO3CO3/sfYzu4Vzv9EUoBIDrJjlKRSUTeA542xjza17Go8KFJQakIJCKnAu9g+0Rq+zoeFT60+UipCCMiT2DvYbhDE4JqT88UlFJK+eiZglJKKZ9+N6hWVlaWyc/P7+swlFKqX1m1atVhY0z7e186CFlSEJHHsLfalxljTgrwvgC/x1661wDMN8as7m6/+fn5FBUV9XS4Sil1QhORvd2vFdrmo78Ds7t4fw5Q4DwWYu/OVEop1YdClhSMMcuwN+d05nLgH8ZaDqSLSG6o4lFKKdW9vuxoHkrbAb6KnWUdiMhCESkSkaLy8vJeCU4ppSJRXyYFCbAs4PWxxphHjDHTjTHTs7O77SdRSil1jPoyKRRjR7NslYcd8VIppVQf6cuk8ArwdWd0ytOxY7of7MN4lFIq4oXyktRngLOBLGfu2Z9jZ8HCGPMwdtrEi7AjUzYAC0IVi1JKqeCELCkYY67r5n0D3Bqq4yul1HExBrwtEB3bs/ttOALrF8OAoZBbCGlDQAJ1sfaNfndHs1JKHbfaUtj5LrQ0HV1mDNSXQ8UO57HTvj/1RjjrBzAgr+0+yrbA8oeg5iCc/m0YfV73hburHp6aCwdWHV2WnANDCiG53UU0cckweLJNHDkTej45daLfDYg3ffp0o3c0q37P1QCxiaGvIdaUwJFdkJoLKYMgPqX7bdqrPgAbFkN0HKQOPrqvtKEQExd4m6YaKN0Aze0GYXU3Ql0p1B60BXNDBUy4BApvgKjojvtpcUHxZ/Z46SM6P14wmqph86uw/nnYvQyMN8BKAgOGQdYYyBwD7gb43Jm76JSv2+RwZBd88gfY/jbEJEBihv08eTPg7Lth9LmBf68eNzwzD3a+B1c/ao9TshZK1sDBz6G5pu36jVXgcr6/6HgYfBKcdSeMv/iYPr6IrDLGTO92PU0KSjmaa+0/btLAntunMbZgLt0IB9ceLQRqSyBhgC14Mgvsz9yTYfjpkJDWcT+Ve2Hfp/Zn7cGjBWvaULj0QUjO7LjNvuXw1FfbFjZxqbbZorUGOqQQBk8JfMyDn8Mnf4SNL9hmlPYkCtKHH40/JdvWnkvW2Jp24CvMragYSBlsa7+VuyFnIlxwH4w53xaojZVQ9BiseATqDjnHi4aMfHusxIy2+4uOsYmjNWGl5Nha/+HttsZfscPG5WmGjJEw+asw8XJIzmq7n4QBNln7q9oHHz4Aa550vgcDSVkwYyGc+g2IT4W1T8Gy30BNsU0OZ/0ACi6EKOdaHq8XXvo2rHvO/r6m3dT5d9PK67XfTcmao4njjO/B2Au73zYATQqRytNia1y91UZpjK05HVwLtYdsjS8xPbTHdDXYz9f+n9c/pqZq+w91uLUpYLv9573gPvuP317lXvjHZbZWPP5imL4A8mcd/af2tNh/yr0f29pjXIo9vY9PtQWbqx6a62zNrqkGqvYebYJwNzgHEVugDZkKWWNtod7aVFFzwFkl2hbU+WfaAnD/StjzEVTvOxprUpatsafkwJ6PbZv0Dc9DVsHRdXa9D89cZ9+78P/aWmftQfs7qtprP0vrMRG7r9ZCNXUQVO6xtem4FFtDPu1bEJ/m7MPZT+Xeo99t6+dMHWLjb0047Qvd6Dh7jMSB9rs1Bja9DEvusb+vUWfb72bNU+Cut7XuafPtGcbh7Ue/r/ZnIB4X1JWB8XT83aYMcpJuIZx0NQw95dj+P6r2QdHjkDECplzb8e+vpdkmjo9+C9X7bbI847swZR4s/YU9uzj3v2DWj774sXuAJoVI46qHZb+2NbsBeTBuDoydDSPO6LwtsuHI0X+ymARbqAwcDXFJXR/L3Qir/wFbXrOFS1P10feGnAI3vhg4Max50j5Gfhkmz21biLWqK7eFTGvB0/qo83veWvONH+A0Zwy2BX394aPbtTT67VQgfZitsWcWwPXP2X/sVoe3wxOX2ULtpKttzbixEgaOsgmibIutpbvquv5eWkXFOE0QTg06cwxkj4fcKTaJBNJcBweKbALY8xEUF4HXDUmZMGIm5J8F+TNt/P5NKPs/s4W/1w3XPgkjZ8HWN2DRTfa4X3/JFviB1JXZM5eDn9ukU3voaLNOTIKtBU+bH1ySN8YW1IHOOILR4rJnBh/8r93P5K/Cl261TSbB8npsc1TtQfvZkjIhc3TgSkAoedw20X3yoP1u4wdAc7U9s5jz/4JKSB6vwdXiJTEuQJPaMdKk0F95vbYTatsbcGi9rd3knwnDZgSuGRsDm1+BN39iT10nXWX/qXYvs6fK8Wn21Fz8bknxNNvafWNl4BjS8mzHVsEFNrG0FqDuRlj1hK0J1R2CQZMhb7qt+Q4ptDWp5xfYpgn/xOD1wrv3wMe/hwHDbS0K49TcrrIFQmvTSk27ueqj423NNTXXqR0Ptq+hbdJoqrYdda1JImUQDBxpC8aMkRCbALs+gEU32trqvGdg2KlwaAP88wq7vxtfsoWQu8n+U6/6O+z7BLLG2d9B/pm2gE7Osgmiuc7+9LjsWUNcqm2zj0k4/jM1V4Mt3DJGHj1b6UzlHnj6Wpvcpy2AVY/bJqGv/atnm8J6g6vefp/tm4f6iSa3h2XbyklLjGVUVhLZFSuR5Q/bxHzxbzr0m3i8hj0V9Ww7VMu20jp2lNexvbSWXYfr8XoNp40ayIWTBnPBxEHkDujkzDhImhTCWVONLXRc9X4LjS2gtr9l20Il2tZUj+y0HWLRcZB3qm1SiEuxhU9ciq1V7nwXBp1k/+iGn25356qHnUth25u20PAXFXO0bbb17KCl0RYqrc0tB1bZGjvYpDLiDNj8mk0GI2bC2T+GkWd1/GxbXodFX7e14htfhKhYeHGh7eCb/g1bU6ovt7Xx9c/btlI4eno/ZKpNSGlDbMGemNGzTWHl2+Dpr9orRr78I3tmFZcMX3/Fdi62526yCSXcNVbB8/Nh11L7+7nu2WOvtZ/g3B4veyvq2Vthm/XiYqKIjbaPYQMTyUn94r/v6gY3T67Yy+Mf7+Zwncu3PDU+hpHZyeSkxhMbHeU7lsdr2F5Wy/bSOppbjnZ4DxuYSEFOKmNyUhCBJZtK2Vluy4kpeQO44/wCzh0/6Jg+tyaFcNRUA589Ap/+MXAtPWEAjHFq5wXn2wKxqdp2GO75EPZ+Yk/tXbW2lmo89kzgnJ/CqTfbzraeVLHTNkVse9Mee9hpcM6PbRNFV7b82zZf5E6xZzIla2y79um3dCzgqw/YBNebp/j1FfDs9bB/ua2Jf/3lts1J/ZXHba+IGXVO902A/VBFXTMrdh/hs91HyB2QwLxThzMgqWPT6OG6Zv697iCH65pxeby4Wry4PV4q6lxsL6tjz+F6Wrydl3sFOSnMHJPFzDFZjB+cyq7D9WwqqWHTwRq2HqohITaavIxE8jKSyMtIZP+RBp5esY96l4dZY7P5j5n5RImw+3A9u8rr2HW4niP1Ll8cLicJjM5JYeygVMYNTmX8YJsIkuI6/g/vKKvjnU2lvLXxEN87dwznTdCk0Ea/TArNtbDiL0eTwdjZtrNp4Ki268WnBV+wG2OvoZbo47tML1heT+BLBjuz5d/2jCE6Hub+zfZxhBN3E6x9EsZfYpub1HHxeg2VDS4GJMYSE922uavJ7WHzwRrWH6jmcG0zo3NSGD84jVHZycQ661Y3un2F6OG6ZtweQ7NTiFY3uinac4RtpbZPJz4miuYWL4mx0Vw9bSgLZo5kVFYyn+6s4OnP9vHWxkO4PQYRiIuOso+YKAYkxjI6J4WCnBQKBqWQn5lMdJTgavHi8nhpbvGy9VAtH+84zMo9R2hyt71kdWh6IhNyU3F5DMWVDRRXNuJq8RIdJVwyJZdvzRrNxCHhe3amSSEceFpg9d/h/V/ZJpOxs+HLd9mrHyLBgdU20QVqllG9zuM1vPp5Ca+vP0h6UiyD0hLISUsgJzWe/Mxk8rOSiI85mvhdLV6K9h7h/a3lrNh9hOS4aHIHJDIkPYHcAYk0t3jYeqiWLYdq2V5aS73LgwhkJsczKC2e7NR4Smua2VZaiydAzTw2WhiRmUxVg6tNk4u/uOgoEmKjKByewemjBnL6qEwmDx3AjrI6HvtoNy+vLcHl8TIozR5rQGIsV5+Sx3UzhjlNMMfW9Njc4mH13ip2lNUyOieFSbkDOpyVeL2Gw/XNRImQlRJ/TMfpTZoUQqX+sL1GPGWw7cQL9EdnjG12WfJzOLwNhp8BX/lv2ymr+q0th2r497qDJMXFcFZBFhNz04iKsr9/YwwbDtTw2voS3t9SzrCBicwam81ZBdnkZyZ1WjgdrmvmhdXFvLD6AFEinDM+m3PG5VA4LN1X465qcNmCt6yOmkY3jS4PjW77GJgUxxVThzAmp5OrmpzYlmwu4/63trK1tJYhAxJo8RoO1zXjX1ZHRwkjBiYxJsfe4PbJzgrqmluIjRamDsvA7fVysKqJstom33YDk+MY5zSBDB+YRHWjm7LaJkprmimrbWJgcjyTh6YxeWg6k/MGkJUSx67yel8y2Vlex8CkOEZlJzMyK5lR2SkMHpBAXHQUsdHSbaFeXtvM0yv2sf5ANRdNHsxFk3NJiO25K3ZOJJoUQmHrm/DCN49eEhkdZ5NDcmbbq3uaa20yyCyAC+6FcReF1dgmkaC6wU1cTFTAS/oaXR4Wry7m5TUHGJmVzDnjczizIIu0hI7t02W1TbyytoQXVh9g08EaogRfgZiVEseZY7IYlJbAWxsPsaeigZgo4dT8gRRXNbD/iL0sdtjARE4ZnsFgv5p5dJTwytoSlmwupcVrmDYig5gooWhvJR6vIS0hhgm5aeypqKe0prlNTFECSXExJMRGUdngxuM1FA5LZ+60PC49eQhRgi2Ua5ooqW7i6RV7Wb2vivzMJH7wlXFcMjmXqCjB4zVU1DVzqKaJ3Yfr2VFWx3bnCpgmt4ezCrI5Z1w2Z4zJIiX+aLNmi8dLWW0zMdFCdkr8MdfGVe/SpNCTvF748H5Y+kt7qd/M221zUOvlkA0VtL17U2DcbDjlpl4br0RZrhYvD3+wkz++twMRmDkmi/Mm5HDe+EFERwn//HQP/1y+l8oGN2MHpVBa00x1o5voKGHaiAyGD0yirNYWqKU1TVQ2uAF75cdVU4dy6clD8HgNH+04zLJt5Xy4/TBVjW7OGJ3JxZNzuXDSYDKSbR/PnsP1LNtezrJt5Ww+WEt5re34bJWZHMfV0/K4Znqer6Zf3ejm4x2HWbqljG1ldYzOSmbc4FTfIzM5vk0Nury2mZfXHuD5omK2lra7ocsxOC2B288vYO60PF8bvoo8mhR6SnMtvPhte6PWlGvh0t93fietCqkmt4fP91dRtLeSmCjhTKcJp7WAXL2vkrv/tY5tpXVcPDmX7NR43t1S6quxx0YLbo/h/AmDWDhrFKfmZ+DxGtbur2Lp1jLe31pORZ2LQWnx5KQlMCgtniHpiXxl4mBfk0p7Xq+hqcUT8KqR9owxVDe6Ka1pprbJzZS8dOJieqaQNsawsaSGdzaVkhwfbfsLUhPISYtnWEZSjx1H9V+aFHpC+TZ7s9Ph7bZP4PTvaDNQL6pvbqFobyXLd1Xw2e4jrC+ublPTBshKiWdWQRbxsVE8u3I/g9MS+O/LT+L8ifayPWMM28vqWLK5lMp6F/NmDGd09jEMCqdUPxdsUtChszuzbhG8eoe9cenGF+yYLKpHVdQ18+TyfVQ3ukmMiyIxNpqE2Ggq6l0s31XBuuJqPF5DTJQwOW8AC2bmc2r+QKbnZ9Dc4vU137y/rZzKBhdfP30EP7xwHKl+fQMiwthBqYwd1HlHrFLqKD1TaM/dCG/cBaufsFcNzf2bvbtWdcntsdd4H65rpqrBTWWDi6oGN4PSEjh7XDZD0o82udU2uXn0w908+uEuGtwekuNiaHR7fJctxkQJJw9L912COG1ERpfNM16voba5hQGJ2n+jVGf0TOFYHNkFz91ox4E/8wf2TuGevkv4BNBaCO8sr2P5rgqW7zpC0Z4jNLgCjFDpGD84lbPH5ZCaEMOjH+6issHNnJMGc+dXxvo6Wd0eL41uj3NtevCXFUZFiSYEpXqIlnj+Xv9PO1jbDYvtYHARptHlYUNJNWv3VbGzvI7a5hbqnUdds4faJjc1jW5qm1vwP8EcNyiVr07LY3r+QIakJ5CeFEdGUhwDEmPZVV7H0q1lLN1SzqMf7qLFazirIIsfXTiOKXltR99sHX9GKdV3Iicp7HwP1j0PV/wpcGdxU7Udg/60b53QCcHtXGNefMTepl9c2cj+ygY2ldSw1e/O06yUeNISY0iJjyE5Loah6XGkJaaSlhBLWkIMaYmxDElPZMbIgV3ezVkwKJWCQaksnDWa2iY35bXNjNKOXqXCVuQkheoD8PnTMP0/7JDJ7W1/x45JP+HS3o+th7g9Xl5ac4CD1U1O7d7W8isb3L5r7yvqOw4nkJMaz7jBqdwyfjSFw9I5eVg62ak9f9t+akJsm05gpVT4iZykMPFyeP2HsO7ZwElh86t2Au28Gb0fWw/Yf6SB255dw5p9VYAdNCw5Pobk+GjSE+MYmp7A1OHpDHKuXW8d5TF3QIIOC6CU8omcpJCQZoeb2PACXPg/bUcWdTfBjiV2NrDuJjQJQ69+XsJPXlgPwB+um8rskwZr27xS6phEVslx8jxoPGITgL9d79sZtMb3r6ajmiY3/7n4c773zBrGDErh9dvP4tKTh2hCUEods8g5UwA7CXhSlm1CGn/R0eVbXrVDPHc3eUwY8HoNn+6qYPGqYt7YcJDmFi/fPWcMt59foMlAKXXcIispRMfaJqKix+30hYnpds6DrW9AwVd6Z7KaL8jjNew+XM+mgzWsL67i9fWHOFDVSGpCjDNu/HBOGtrLE5MrpU5YkZUUAKZcAysehk0vwbT5dkrGhgqYcElfR9bGxzsO88A729hUUkOj294UFhstnD4qk7vmjOcrEwdpB7FSqsdFXlIYcoqd5+Dz52xS2PyanTJyTHjcm+D1Gh5auoMHlmxj+MAk5s0YxsTcNCYOSaMgJ1VHu1RKhVTkJQUROPlaeO8XULnXDok9+lw7eXwfO1Lv4vvPreWDbeVcUTiEX145meT4yPsVKaX6TmRWOydfY3++/VM7rEUYNB2t3HOESx78kE93VvCLK07it9cWakJQSvW6yCx1MkbAiJn2hjWJgrFz+iyUrYdquf/trbyzqZRhAxP51y1nMDlPO46VUn0jpElBRGYDvweigUeNMb9q9/4I4DEgGzgCfM0YUxzKmHymXAt7P7bJITmzVw7pb19FA79dso2X1h4gJS6GOy8Yy4IzR7aZC1cppXpbyEogEYkGHgIuAIqBlSLyijFmk99q9wP/MMY8ISLnAv8D3BiqmNqYeDm8ex8UXt8rh2tVWe/iwfe28+TyvUSJsHDWKL49a7RvXl+llOpLoayWzgB2GGN2AYjIs8DlgH9SmAh833m+FHgphPG0lZgOP9rRa9NrNrk9/P2TPTy0dAf1zS1ce+ow7jh/LIPSEnrl+EopFYxQJoWhwH6/18XAae3W+Ry4GtvEdCWQKiKZxpgK/5VEZCGwEGD48OE9F2EvJYS3Nx7i3lc3caCqkXPH53D3nPE6PaRSKiyFMikEKnHbz/35Q+CPIjIfWAYcAFo6bGTMI8AjYKfj7NkwQ6fB1cJ/v7aZZz7bx4TcNH49dwpnjMnq67CUUqpToUwKxcAwv9d5QIn/CsaYEuAqABFJAa42xlSHMKZes+FANbc9u4bdh+v51pdHcecF4/TGM6VU2AtlUlgJFIjISOwZwDygTa+uiGQBR4wxXuDH2CuR+rUWj5dHP9rNb97eysDkOJ76xml6dqCU6jdClhSMMS0i8l3gLewlqY8ZYzaKyH1AkTHmFeBs4H9ExGCbj24NVTy94bPdR/jZyxvYcqiWCycN4ldXTdGripRS/YoY02+a6AHbp1BUVNTXYbRRVtvEr17fwgtrDjA0PZH/c8lELpw0COmljmyllOqOiKwyxkzvbj29U+o4rdhVwc1PFPnmNbj1nDEkxunopUqp/kmTwnGob27hB4s+Jys1nr/dNJ1R2X0/qJ5SSh0PTQrH4ddvbaWkupHnv/UlTQhKqROCXiN5jFbuOcLfP9nDTV/KZ3r+wL4ORymleoQmhWPQ5PZw1+J15GUk8qMLx/V1OEop1WO0+egY/HbJNnYdrufJb5ymcx4opU4oeqbwBX2+v4q/LtvFvFOHcWaB3pSmlDqxaFL4Arxew09fWk92ajw/uXhCX4ejlFI9TpPCF/DWxkNsOFDDXbPHk5YQ29fhKKVUj9OkECSP1/DbJdsYnZ3M5YVD+zocpZQKCU0KQXptXQnbSuu44/yxREfp8BVKqROTJoUgtHi8/H7JdsYPTuXiybl9HY5SSoWMJoUgvLS2hF2H67nj/LFE6VmCUuoEpkmhG26Plwff3c6kIWlcOGlQX4ejlFIhpUmhG4tXFbPvSAM/uGCsDoWtlDrhaVLoQnOLhz++t4PCYemcOz6nr8NRSqmQ06TQhXc2lXKgqpHbzyvQswSlVETQpNCFl9aUMCgtnlljs/s6FKWU6hWaFDpR1eDig21lXDpliN6XoJSKGJoUOvH6+kO4PYYrpurdy0qpyKFJoRMvrz3AqOxkJg1J6+tQlFKq12hSCKCkqpHP9hzhisKh2sGslIoomhQCePXzEoyBy04e0tehKKVUr9KkEMDLa0soHJZOflZyX4eilFK9SpNCO9tLa9l0sIbLC/UsQSkVeTQptPPy2hKiBC6eoqOhKqUijyYFP8YYXv78ADPHZJGTmtDX4SilVK/TpOBn9b4q9h9p1JnVlFIRS5OCn9fWlRAfE6VDZCulIpYmBT8bS2qYkjeA1ITYvg5FKaX6hCYFP7vK6xidndLXYSilVJ8JaVIQkdkislVEdojI3QHeHy4iS0VkjYisE5GLQhlPV6oaXByuc2lSUEpFtJAlBRGJBh4C5gATgetEZGK71f4LWGSMmQrMA/4Uqni6s7O8DoDROXrDmlIqcoXyTGEGsMMYs8sY4wKeBS5vt44BWkecGwCUhDCeLu0sqwdgTHZqX4WglFJ9LpRJYSiw3+91sbPM3z3A10SkGHgd+F6gHYnIQhEpEpGi8vLyUMTKzvI64mKiGJqRGJL9K6VUfxDKpBBoeFHT7vV1wN+NMXnARcA/RaRDTMaYR4wx040x07OzQzML2s7yOkZlJeuEOkqpiBbKpFAMDPN7nUfH5qFvAIsAjDGfAglAVghj6tTO8nrtZFZKRbxQJoWVQIGIjBSROGxH8ivt1tkHnAcgIhOwSSE07UNdaG7xsLeintHZ2smslIpsIUsKxpgW4LvAW8Bm7FVGG0XkPhG5zFnl5OWnAAAXs0lEQVTtTuCbIvI58Aww3xjTvokp5PZWNOA1MDpHzxSUUpEtJpiVRORfwGPAG8YYb7A7N8a8ju1A9l/2M7/nm4CZwe4vVHaWOZejavORUirCBXum8GfgemC7iPxKRMaHMKZe13qPwihtPlJKRbigkoIxZokx5gbgFGAP8I6IfCIiC0Sk3w8UtLO8nqHpiSTFBXXipJRSJ6yg+xREJBOYD9wMrAF+j00S74Qksl60o6xOzxKUUoogk4KIvAB8CCQBlxpjLjPGPGeM+R7QrxvijTHs1IHwlFIKCLKjGfijMea9QG8YY6b3YDy97lBNEw0uj155pJRSBN98NEFE0ltfiEiGiHwnRDH1qqNjHmlSUEqpYJPCN40xVa0vjDGVwDdDE1Lv0tFRlVLqqGCTQpSI+AYFcobFjgtNSL1rR1kdqQkxZKfE93UoSinV54LtU3gLWCQiD2MHtfs28GbIoupFrZ3MfjlPKaUiVrBJ4S7gW8At2NFP3wYeDVVQvWlneR1njgnNyKtKKdXfBJUUnKEt/uw8Thi1TW5Ka5oZo1ceKaUUEPzYRwXA/2Cn1UxoXW6MGRWiuHrFrnJ75ZGOjqqUUlawHc2PY88SWoBzgH8A/wxVUL1lR+tAeHqmoJRSQPBJIdEY8y4gxpi9xph7gHNDF1bv2FleR0yUMHxgUl+HopRSYSHYjuYmZ5rM7SLyXeAAkBO6sHrHzvI6RmQmERsdyrmGlFKq/wi2NLwDO+7RbcA04GvATaEKqrfoFJxKKdVWt0nBuVHtGmNMnTGm2BizwBhztTFmeS/EFzItHq+dglP7E5RSyqfbpGCM8QDT5AS7u6umqQW3x5CTqncyK6VUq2D7FNYAL4vI80B960JjzAshiaoXNLhaAEiKi+7jSJRSKnwEmxQGAhW0veLIAP02KTS6PAAk6mxrSinlE+wdzQtCHUhvq3eSQrKeKSillE+wdzQ/jj0zaMMY8x89HlEvaW0+StSkoJRSPsG2nbzm9zwBuBIo6flwek9r81GSNh8ppZRPsM1H//J/LSLPAEtCElEvafAlBT1TUEqpVsd6K28BMLwnA+ltvo7mWE0KSinVKtg+hVra9ikcws6x0G+19ikkx2vzkVJKtQq2+Sg11IH0tnptPlJKqQ6Caj4SkStFZIDf63QRuSJ0YYVeo8uDCMTH6GB4SinVKtgS8efGmOrWF8aYKuDnoQmpdzS4PCTFRuvczEop5SfYpBBovX7dGN/obtG7mZVSqp1gk0KRiDwgIqNFZJSI/BZY1d1GIjJbRLaKyA4RuTvA+78VkbXOY5uIVH3RD3CsGlwe7U9QSql2gk0K3wNcwHPAIqARuLWrDZwhtx8C5mDndr5ORCb6r2OM+b4xptAYUwj8gV4cS0mTglJKdRTs1Uf1QIeafjdmADuMMbsARORZ4HJgUyfrX0cv9lM0uFo0KSilVDvBXn30joik+73OEJG3utlsKLDf73WxsyzQ/kcAI4H3Onl/oYgUiUhReXl5MCF3y54paJ+CUkr5C7b5KMu54ggAY0wl3c/RHOiyng6D6jnmAYudCX06bmTMI8aY6caY6dnZ2UEF3J1Gl0cHw1NKqXaCTQpeEfENayEi+XRewLcqBob5vc6j80H05gHPBBlLj9A+BaWU6ijY9pOfAh+JyAfO61nAwm62WQkUiMhI4AC24L++/UoiMg7IAD4NMpYeoc1HSinVUVBnCsaYN4HpwFbsFUh3Yq9A6mqbFuC7wFvAZmCRMWajiNwnIpf5rXod8Kwxprszjx7VqB3NSinVQbAD4t0M3I5tAloLnI6t2Z/b1XbGmNeB19st+1m71/cEH27PMMbQ4NbmI6WUai/YPoXbgVOBvcaYc4CpQM9cBtQHmtxejNFZ15RSqr1gk0KTMaYJQETijTFbgHGhCyu0WofNTtK5FJRSqo1ge1qLnfsUXgLeEZFK+vF0nL5Z13QuBaWUaiPYO5qvdJ7eIyJLgQHAmyGLKsQa3TqXglJKBfKFq8rGmA+6Xyu81Tc7zUeaFJRSqo2InGHm6PzM2nyklFL+IjIpNOhUnEopFVBkJgXtU1BKqYAiMik0tl6SqlcfKaVUGxGZFHzNR3qfglJKtRHRSUHvaFZKqbYiNCm0ECUQHxORH18ppToVkaVi67DZIoHmAVJKqcgVkUmhUSfYUUqpgCIyKeisa0opFVjEJoVEnXVNKaU6iNCkoLOuKaVUIBGaFLT5SCmlAonIpNDo8pCoN64ppVQHEZkUGtwtJOsQF0op1UFEJoVGl0fvZlZKqQAiMik0uDw67pFSSgUQcUnB6zXa0ayUUp2IuKTQ1NI6GJ72KSilVHsRlxRaR0hNjtczBaWUai/iksLR+Zk1KSilVHsRlxSOzs+szUdKKdVeBCYFZypO7WhWSqkOIjAp6KxrSinVmYhNCsnafKSUUh1EYFKwzUd6pqCUUh2FNCmIyGwR2SoiO0Tk7k7WuUZENonIRhF5OpTxwNGrj7RPQSmlOgpZG4qIRAMPARcAxcBKEXnFGLPJb50C4MfATGNMpYjkhCqeVg2aFJRSqlOhPFOYAewwxuwyxriAZ4HL263zTeAhY0wlgDGmLITxANp8pJRSXQllUhgK7Pd7Xews8zcWGCsiH4vIchGZHWhHIrJQRIpEpKi8vPy4gmpweYiOEuKiI647RSmluhXKklECLDPtXscABcDZwHXAoyKS3mEjYx4xxkw3xkzPzs4+rqBaB8MTCRSeUkpFtlAmhWJgmN/rPKAkwDovG2PcxpjdwFZskgiZRh0hVSmlOhXKpLASKBCRkSISB8wDXmm3zkvAOQAikoVtTtoVwphocHt0iAullOpEyJKCMaYF+C7wFrAZWGSM2Sgi94nIZc5qbwEVIrIJWAr8yBhTEaqYABpdLToYnlJKdSKkVWZjzOvA6+2W/czvuQF+4Dx6RX2zNh8ppVRnIu4SnAa3h6R4bT5SSqlAIi4pNLpadH5mpZTqRMQlBZ2fWSmlOhdxSaHR5dG7mZVSqhMRlxT0TEEppToXUUnB6zU06n0KSinVqYhKCo1uHSFVKaW6ElFJQYfNVkqprkVUUmj0zc+szUdKKRVIRCWFBredS0HPFJRSKrDISgq+MwVNCkopFUhEtaM0NNukkKzNR0qFDbfbTXFxMU1NTX0dygkhISGBvLw8YmNjj2n7iCodW6fi1OYjpcJHcXExqamp5Ofn6+RXx8kYQ0VFBcXFxYwcOfKY9hFRzUetl6Rq85FS4aOpqYnMzExNCD1ARMjMzDyus66ISgp6SapS4UkTQs853u8yMpNCbES1mimlVNAiKik0On0K2nyklGpVVVXFn/70py+83UUXXURVVVWX6/zsZz9jyZIlxxpan4iopFDv8hAbLcTFRNTHVkp1obOk4PF4utzu9ddfJz09vct17rvvPs4///zjiq+3RVQ7SqPLo/MzKxXG7n11I5tKanp0nxOHpPHzSyd1+v7dd9/Nzp07KSwsJDY2lpSUFHJzc1m7di2bNm3iiiuuYP/+/TQ1NXH77bezcOFCAPLz8ykqKqKuro45c+Zw5pln8sknnzB06FBefvllEhMTmT9/Ppdccglz584lPz+fm266iVdffRW3283zzz/P+PHjKS8v5/rrr6eiooJTTz2VN998k1WrVpGVldWj30OwIqrK3OBq0RFSlVJt/OpXv2L06NGsXbuWX//613z22Wf88pe/ZNOmTQA89thjrFq1iqKiIh588EEqKio67GP79u3ceuutbNy4kfT0dP71r38FPFZWVharV6/mlltu4f777wfg3nvv5dxzz2X16tVceeWV7Nu3L3QfNggRVULqXApKhbeuavS9ZcaMGW2u8X/wwQd58cUXAdi/fz/bt28nMzOzzTYjR46ksLAQgGnTprFnz56A+77qqqt867zwwgsAfPTRR779z549m4yMjB79PF9URCWFRpeHpHhNCkqpziUnJ/uev//++yxZsoRPP/2UpKQkzj777ID3AMTHx/ueR0dH09jYGHDfretFR0fT0mIvfDHG9GT4xy2imo/qXS16OapSqo3U1FRqa2sDvlddXU1GRgZJSUls2bKF5cuX9/jxzzzzTBYtWgTA22+/TWVlZY8f44uIqBKy0eUhPSmur8NQSoWRzMxMZs6cyUknnURiYiKDBg3yvTd79mwefvhhpkyZwrhx4zj99NN7/Pg///nPue6663juuef48pe/TG5uLqmpqT1+nGBJuJ26dGf69OmmqKjomLa94IEPGJOTwp+/Nq2Ho1JKHavNmzczYcKEvg6jzzQ3NxMdHU1MTAyffvopt9xyC2vXrj2ufQb6TkVklTFmenfbRtSZQoPLozeuKaXCyr59+7jmmmvwer3ExcXx17/+tU/jiaik0OjWq4+UUuGloKCANWvW9HUYPhHV0dzgatG5FJRSqgsRkxQ8XkOT26vNR0op1YWISQqtcylo85FSSnUuYpJCg2+EVG0+UkqpzoQ0KYjIbBHZKiI7ROTuAO/PF5FyEVnrPG4OVSyNvrkU9ExBKXXsUlJSACgpKWHu3LkB1zn77LPp7tL53/3udzQ0NPheBzMUd28IWVIQkWjgIWAOMBG4TkQmBlj1OWNMofN4NFTxtE6wk6zDXCilesCQIUNYvHjxMW/fPikEMxR3bwhlW8oMYIcxZheAiDwLXA5sCuExO9WaFLT5SKkw9sbdcGh9z+5z8GSY86tO377rrrsYMWIE3/nOdwC45557EBGWLVtGZWUlbrebX/ziF1x++eVtttuzZw+XXHIJGzZsoLGxkQULFrBp0yYmTJjQZuyjW265hZUrV9LY2MjcuXO59957efDBBykpKeGcc84hKyuLpUuX+obizsrK4oEHHuCxxx4D4Oabb+aOO+5gz549nQ7R3ZNC2Xw0FNjv97rYWdbe1SKyTkQWi8iwQDsSkYUiUiQiReXl5ccUTGufgnY0K6X8zZs3j+eee873etGiRSxYsIAXX3yR1atXs3TpUu68884uB67785//TFJSEuvWreOnP/0pq1at8r33y1/+kqKiItatW8cHH3zAunXruO222xgyZAhLly5l6dKlbfa1atUqHn/8cVasWMHy5cv561//6ruPIdghuo9HKKvNgWaPbv+tvgo8Y4xpFpFvA08A53bYyJhHgEfADnNxLMH4zhS0T0Gp8NVFjT5Upk6dSllZGSUlJZSXl5ORkUFubi7f//73WbZsGVFRURw4cIDS0lIGDx4ccB/Lli3jtttuA2DKlClMmTLF996iRYt45JFHaGlp4eDBg2zatKnN++199NFHXHnllb7RWq+66io+/PBDLrvssqCH6D4eoUwKxYB/zT8PKPFfwRjjP1vFX4H/DVUwvo5mPVNQSrUzd+5cFi9ezKFDh5g3bx5PPfUU5eXlrFq1itjYWPLz8wMOme1PpGM9ePfu3dx///2sXLmSjIwM5s+f3+1+ujojCXaI7uMRyuajlUCBiIwUkThgHvCK/woikuv38jJgc6iCafAlBe1TUEq1NW/ePJ599lkWL17M3Llzqa6uJicnh9jYWJYuXcrevXu73H7WrFk89dRTAGzYsIF169YBUFNTQ3JyMgMGDKC0tJQ33njDt01nQ3bPmjWLl156iYaGBurr63nxxRc566yzevDTdi1kJaQxpkVEvgu8BUQDjxljNorIfUCRMeYV4DYRuQxoAY4A80MVj69PQa8+Ukq1M2nSJGpraxk6dCi5ubnccMMNXHrppUyfPp3CwkLGjx/f5fa33HILCxYsYMqUKRQWFjJjxgwATj75ZKZOncqkSZMYNWoUM2fO9G2zcOFC5syZQ25ubpt+hVNOOYX58+f79nHzzTczderUkDQVBRIxQ2e/vfEQL6w+wB+vn0pMdMTcs6dU2Iv0obNDQYfODsJXJg3mK5MCdxIppZSytMqslFLKR5OCUqrP9bdm7HB2vN+lJgWlVJ9KSEigoqJCE0MPMMZQUVFBQkLCMe8jYvoUlFLhKS8vj+LiYo51tALVVkJCAnl5ece8vSYFpVSfio2NZeTIkX0dhnJo85FSSikfTQpKKaV8NCkopZTy6Xd3NItIOdD1QCSdywIO92A4odbf4oX+F7PGG1oab2h9kXhHGGOyu1up3yWF4yEiRcHc5h0u+lu80P9i1nhDS+MNrVDEq81HSimlfDQpKKWU8om0pPBIXwfwBfW3eKH/xazxhpbGG1o9Hm9E9SkopZTqWqSdKSillOqCJgWllFI+EZMURGS2iGwVkR0icndfx9OeiDwmImUissFv2UAReUdEtjs/M/oyRn8iMkxElorIZhHZKCK3O8vDMmYRSRCRz0Tkcyfee53lI0VkhRPvc8584mFDRKJFZI2IvOa8Dtt4RWSPiKwXkbUiUuQsC8u/BwARSReRxSKyxfk7/lKYxzvO+W5bHzUickdPxxwRSUFEooGHgDnAROA6EZnYt1F18HdgdrtldwPvGmMKgHed1+GiBbjTGDMBOB241flOwzXmZuBcY8zJQCEwW0ROB/4X+K0TbyXwjT6MMZDbgc1+r8M93nOMMYV+186H698DwO+BN40x44GTsd9z2MZrjNnqfLeFwDSgAXiRno7ZGHPCP4AvAW/5vf4x8OO+jitAnPnABr/XW4Fc53kusLWvY+wi9peBC/pDzEASsBo4DXs3aEygv5O+fgB5zj/5ucBrgIR5vHuArHbLwvLvAUgDduNcbBPu8QaI/yvAx6GIOSLOFIChwH6/18XOsnA3yBhzEMD5mdPH8QQkIvnAVGAFYRyz0xSzFigD3gF2AlXGmBZnlXD7u/gd8J+A13mdSXjHa4C3RWSViCx0loXr38MooBx43Gmee1REkgnfeNubBzzjPO/RmCMlKUiAZXotbg8QkRTgX8Adxpiavo6nK8YYj7Gn3nnADGBCoNV6N6rAROQSoMwYs8p/cYBVwyJex0xjzCnYZtpbRWRWXwfUhRjgFODPxpipQD1h1FTUFacf6TLg+VDsP1KSQjEwzO91HlDSR7F8EaUikgvg/Czr43jaEJFYbEJ4yhjzgrM4rGMGMMZUAe9j+0LSRaR1sqlw+ruYCVwmInuAZ7FNSL8jfOPFGFPi/CzDtnXPIHz/HoqBYmPMCuf1YmySCNd4/c0BVhtjSp3XPRpzpCSFlUCBc+VGHPbU65U+jikYrwA3Oc9vwrbbhwUREeBvwGZjzAN+b4VlzCKSLSLpzvNE4Hxsx+JSYK6zWtjEa4z5sTEmzxiTj/17fc8YcwNhGq+IJItIautzbJv3BsL078EYcwjYLyLjnEXnAZsI03jbuY6jTUfQ0zH3dYdJL3bMXARsw7Yj/7Sv4wkQ3zPAQcCNrcV8A9uG/C6w3fk5sK/j9Iv3TGzTxTpgrfO4KFxjBqYAa5x4NwA/c5aPAj4DdmBPx+P7OtYAsZ8NvBbO8Tpxfe48Nrb+j4Xr34MTWyFQ5PxNvARkhHO8TsxJQAUwwG9Zj8asw1wopZTyiZTmI6WUUkHQpKCUUspHk4JSSikfTQpKKaV8NCkopZTy0aSgVC8SkbNbRzxVKhxpUlBKKeWjSUGpAETka878C2tF5C/OYHp1IvIbEVktIu+KSLazbqGILBeRdSLyYut49iIyRkSWOHM4rBaR0c7uU/zG8X/KuTtcqbCgSUGpdkRkAnAtdoC3QsAD3AAkY8ecOQX4APi5s8k/gLuMMVOA9X7LnwIeMnYOhzOwd6yDHVH2DuzcHqOw4xwpFRZiul9FqYhzHnYSk5VOJT4RO8iYF3jOWedJ4AURGQCkG2M+cJY/ATzvjAM01BjzIoAxpgnA2d9nxphi5/Va7DwaH4X+YynVPU0KSnUkwBPGmB+3WSjyf9qt19UYMV01CTX7Pfeg/4cqjGjzkVIdvQvMFZEc8M0zPAL7/9I6Qun1wEfGmGqgUkTOcpbfCHxg7NwSxSJyhbOPeBFJ6tVPodQx0BqKUu0YYzaJyH9hZxGLwo5ceyt2IpZJIrIKqMb2O4Adrvhhp9DfBSxwlt8I/EVE7nP28dVe/BhKHRMdJVWpIIlInTEmpa/jUCqUtPlIKaWUj54pKKWU8tEzBaWUUj6aFJRSSvloUlBKKeWjSUEppZSPJgWllFI+/x90rP/VntHhygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0543\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# model.fit(X_train, y_train, batch_size=32, epochs=100, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=32, epochs=70, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "loss, accuracy  = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "print(f'Test loss: {loss:.3}')\n",
    "print(f'Test accuracy: {accuracy:.3}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model/model_9_positions.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
